{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# insightFace_Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T11:15:27.582440Z",
     "start_time": "2020-07-20T11:15:21.178157Z"
    }
   },
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import transforms as trans\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# from data.data_pipe import de_preprocess, get_train_loader, get_val_data\n",
    "# from model import Backbone, Arcface, MobileFaceNet, Am_softmax, l2_norm\n",
    "# from verifacation import evaluate\n",
    "# from utils import get_time, gen_plot, hflip_batch, separate_bn_paras\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "from matplotlib import pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "from PIL import Image\n",
    "from torchvision import transforms as trans\n",
    "import math\n",
    "import bcolz\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, Sigmoid, Dropout2d, Dropout, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Sequential, Module, Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "from scipy import interpolate\n",
    "import datetime\n",
    "import mxnet as mx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:12:45.306177Z",
     "start_time": "2020-07-17T05:12:45.303180Z"
    }
   },
   "source": [
    "### utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T11:15:54.773202Z",
     "start_time": "2020-07-20T11:15:54.757200Z"
    }
   },
   "outputs": [],
   "source": [
    "def separate_bn_paras(modules):\n",
    "    if not isinstance(modules, list):\n",
    "        modules = [*modules.modules()]\n",
    "    paras_only_bn = []\n",
    "    paras_wo_bn = []\n",
    "    for layer in modules:\n",
    "        if 'model' in str(layer.__class__):\n",
    "            continue\n",
    "        if 'container' in str(layer.__class__):\n",
    "            continue\n",
    "        else:\n",
    "            if 'batchnorm' in str(layer.__class__):\n",
    "                paras_only_bn.extend([*layer.parameters()])\n",
    "            else:\n",
    "                paras_wo_bn.extend([*layer.parameters()])\n",
    "    return paras_only_bn, paras_wo_bn\n",
    "\n",
    "def hflip_batch(imgs_tensor):\n",
    "    hfliped_imgs = torch.empty_like(imgs_tensor)\n",
    "    for i, img_ten in enumerate(imgs_tensor):\n",
    "        hfliped_imgs[i] = hflip(img_ten)\n",
    "    return hfliped_imgs\n",
    "\n",
    "def get_time():\n",
    "    return (str(datetime.now())[:-10]).replace(' ','-').replace(':','-')\n",
    "\n",
    "def gen_plot(fpr, tpr):\n",
    "    \"\"\"Create a pyplot plot and save to buffer.\"\"\"\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"FPR\", fontsize=14)\n",
    "    plt.ylabel(\"TPR\", fontsize=14)\n",
    "    plt.title(\"ROC Curve\", fontsize=14)\n",
    "    plot = plt.plot(fpr, tpr, linewidth=2)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='jpeg')\n",
    "    buf.seek(0)\n",
    "    plt.close()\n",
    "    return buf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_pipe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T13:18:12.176098Z",
     "start_time": "2020-07-20T13:18:12.145100Z"
    }
   },
   "outputs": [],
   "source": [
    "def de_preprocess(tensor):\n",
    "    return tensor*0.5 + 0.5\n",
    "    \n",
    "def get_train_dataset(imgs_folder):\n",
    "    train_transform = trans.Compose([\n",
    "        trans.RandomHorizontalFlip(),\n",
    "        trans.ToTensor(),\n",
    "        trans.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    ds = ImageFolder(imgs_folder, train_transform)\n",
    "    class_num = ds[-1][1] + 1\n",
    "    print('class_num', class_num)\n",
    "    return ds, class_num\n",
    "\n",
    "def get_train_loader(conf):\n",
    "    if conf.data_mode in ['ms1m', 'concat']:\n",
    "        ms1m_ds, ms1m_class_num = get_train_dataset(conf.ms1m_folder/'imgs')\n",
    "        print('ms1m loader generated')\n",
    "    if conf.data_mode in ['vgg', 'concat']:\n",
    "        vgg_ds, vgg_class_num = get_train_dataset(conf.vgg_folder/'imgs')\n",
    "        print('vgg loader generated')        \n",
    "    if conf.data_mode == 'vgg':\n",
    "        ds = vgg_ds\n",
    "        class_num = vgg_class_num\n",
    "    elif conf.data_mode == 'ms1m':\n",
    "        ds = ms1m_ds\n",
    "        class_num = ms1m_class_num\n",
    "    elif conf.data_mode == 'concat':\n",
    "        for i,(url,label) in enumerate(vgg_ds.imgs):\n",
    "            vgg_ds.imgs[i] = (url, label + ms1m_class_num)\n",
    "        ds = ConcatDataset([ms1m_ds,vgg_ds])\n",
    "        class_num = vgg_class_num + ms1m_class_num\n",
    "    elif conf.data_mode == 'emore':\n",
    "        ds, class_num = get_train_dataset(conf.emore_folder/'imgs')\n",
    "    elif conf.data_mode == 'small_vgg':\n",
    "        ds, class_num = get_train_dataset(conf.smallvgg_folder/'imgs')\n",
    "        \n",
    "    loader = DataLoader(ds, batch_size=conf.batch_size, shuffle=True, pin_memory=conf.pin_memory, num_workers=conf.num_workers)\n",
    "    return loader, class_num \n",
    "\n",
    "def get_val_data(data_path):\n",
    "#     agedb_30, agedb_30_issame = get_val_pair(data_path, 'agedb_30')\n",
    "#     cfp_fp, cfp_fp_issame = get_val_pair(data_path, 'cfp_fp')\n",
    "#     lfw, lfw_issame = get_val_pair(data_path, 'lfw')\n",
    "#     return agedb_30, cfp_fp, lfw, agedb_30_issame, cfp_fp_issame, lfw_issame\n",
    "    lfw, lfw_issame = get_val_pair(data_path, 'lfw')\n",
    "    return  lfw, lfw_issame\n",
    "\n",
    "def get_val_pair(path, name):\n",
    "    carray = bcolz.carray(rootdir = path/name, mode='r')\n",
    "    issame = np.load(path/'{}_list.npy'.format(name))\n",
    "    return carray, issame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T13:18:13.431535Z",
     "start_time": "2020-07-20T13:18:13.297047Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "##################################  Original Arcface Model #############################################################\n",
    "\n",
    "class Flatten(Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "def l2_norm(input,axis=1):\n",
    "    norm = torch.norm(input,2,axis,True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "\n",
    "class SEModule(Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = Conv2d(\n",
    "            channels, channels // reduction, kernel_size=1, padding=0 ,bias=False)\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc2 = Conv2d(\n",
    "            channels // reduction, channels, kernel_size=1, padding=0 ,bias=False)\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "class bottleneck_IR(Module):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(bottleneck_IR, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride ,bias=False), BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3, 3), (1, 1), 1 ,bias=False), PReLU(depth),\n",
    "            Conv2d(depth, depth, (3, 3), stride, 1 ,bias=False), BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "        return res + shortcut\n",
    "\n",
    "class bottleneck_IR_SE(Module):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(bottleneck_IR_SE, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride ,bias=False), \n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3,3), (1,1),1 ,bias=False),\n",
    "            PReLU(depth),\n",
    "            Conv2d(depth, depth, (3,3), stride, 1 ,bias=False),\n",
    "            BatchNorm2d(depth),\n",
    "            SEModule(depth,16)\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "        return res + shortcut\n",
    "\n",
    "class Bottleneck(namedtuple('Block', ['in_channel', 'depth', 'stride'])):\n",
    "    '''A named tuple describing a ResNet block.'''\n",
    "    \n",
    "def get_block(in_channel, depth, num_units, stride = 2):\n",
    "  return [Bottleneck(in_channel, depth, stride)] + [Bottleneck(depth, depth, 1) for i in range(num_units-1)]\n",
    "\n",
    "def get_blocks(num_layers):\n",
    "    if num_layers == 50:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units = 3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=14),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 100:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=13),\n",
    "            get_block(in_channel=128, depth=256, num_units=30),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 152:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=8),\n",
    "            get_block(in_channel=128, depth=256, num_units=36),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    return blocks\n",
    "\n",
    "class Backbone(Module):\n",
    "    def __init__(self, num_layers, drop_ratio, mode='ir'):\n",
    "        super(Backbone, self).__init__()\n",
    "        assert num_layers in [50, 100, 152], 'num_layers should be 50,100, or 152'\n",
    "        assert mode in ['ir', 'ir_se'], 'mode should be ir or ir_se'\n",
    "        blocks = get_blocks(num_layers)\n",
    "        if mode == 'ir':\n",
    "            unit_module = bottleneck_IR\n",
    "        elif mode == 'ir_se':\n",
    "            unit_module = bottleneck_IR_SE\n",
    "        self.input_layer = Sequential(Conv2d(3, 64, (3, 3), 1, 1 ,bias=False), \n",
    "                                      BatchNorm2d(64), \n",
    "                                      PReLU(64))\n",
    "        self.output_layer = Sequential(BatchNorm2d(512), \n",
    "                                       Dropout(drop_ratio),\n",
    "                                       Flatten(),\n",
    "                                       Linear(512 * 7 * 7, 512),\n",
    "                                       BatchNorm1d(512))\n",
    "        modules = []\n",
    "        for block in blocks:\n",
    "            for bottleneck in block:\n",
    "                modules.append(\n",
    "                    unit_module(bottleneck.in_channel,\n",
    "                                bottleneck.depth,\n",
    "                                bottleneck.stride))\n",
    "        self.body = Sequential(*modules)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.body(x)\n",
    "        x = self.output_layer(x)\n",
    "        return l2_norm(x)\n",
    "\n",
    "##################################  MobileFaceNet #############################################################\n",
    "    \n",
    "class Conv_block(Module):\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
    "        super(Conv_block, self).__init__()\n",
    "        self.conv = Conv2d(in_c, out_channels=out_c, kernel_size=kernel, groups=groups, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = BatchNorm2d(out_c)\n",
    "        self.prelu = PReLU(out_c)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.prelu(x)\n",
    "        return x\n",
    "\n",
    "class Linear_block(Module):\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
    "        super(Linear_block, self).__init__()\n",
    "        self.conv = Conv2d(in_c, out_channels=out_c, kernel_size=kernel, groups=groups, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = BatchNorm2d(out_c)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class Depth_Wise(Module):\n",
    "     def __init__(self, in_c, out_c, residual = False, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=1):\n",
    "        super(Depth_Wise, self).__init__()\n",
    "        self.conv = Conv_block(in_c, out_c=groups, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n",
    "        self.conv_dw = Conv_block(groups, groups, groups=groups, kernel=kernel, padding=padding, stride=stride)\n",
    "        self.project = Linear_block(groups, out_c, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n",
    "        self.residual = residual\n",
    "     def forward(self, x):\n",
    "        if self.residual:\n",
    "            short_cut = x\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_dw(x)\n",
    "        x = self.project(x)\n",
    "        if self.residual:\n",
    "            output = short_cut + x\n",
    "        else:\n",
    "            output = x\n",
    "        return output\n",
    "\n",
    "class Residual(Module):\n",
    "    def __init__(self, c, num_block, groups, kernel=(3, 3), stride=(1, 1), padding=(1, 1)):\n",
    "        super(Residual, self).__init__()\n",
    "        modules = []\n",
    "        for _ in range(num_block):\n",
    "            modules.append(Depth_Wise(c, c, residual=True, kernel=kernel, padding=padding, stride=stride, groups=groups))\n",
    "        self.model = Sequential(*modules)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class MobileFaceNet(Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super(MobileFaceNet, self).__init__()\n",
    "        self.conv1 = Conv_block(3, 64, kernel=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.conv2_dw = Conv_block(64, 64, kernel=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
    "        self.conv_23 = Depth_Wise(64, 64, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
    "        self.conv_3 = Residual(64, num_block=4, groups=128, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv_34 = Depth_Wise(64, 128, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
    "        self.conv_4 = Residual(128, num_block=6, groups=256, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv_45 = Depth_Wise(128, 128, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)\n",
    "        self.conv_5 = Residual(128, num_block=2, groups=256, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv_6_sep = Conv_block(128, 512, kernel=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.conv_6_dw = Linear_block(512, 512, groups=512, kernel=(7,7), stride=(1, 1), padding=(0, 0))\n",
    "        self.conv_6_flatten = Flatten()\n",
    "        self.linear = Linear(512, embedding_size, bias=False)\n",
    "        self.bn = BatchNorm1d(embedding_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.conv2_dw(out)\n",
    "\n",
    "        out = self.conv_23(out)\n",
    "\n",
    "        out = self.conv_3(out)\n",
    "        \n",
    "        out = self.conv_34(out)\n",
    "\n",
    "        out = self.conv_4(out)\n",
    "\n",
    "        out = self.conv_45(out)\n",
    "\n",
    "        out = self.conv_5(out)\n",
    "\n",
    "        out = self.conv_6_sep(out)\n",
    "\n",
    "        out = self.conv_6_dw(out)\n",
    "\n",
    "        out = self.conv_6_flatten(out)\n",
    "\n",
    "        out = self.linear(out)\n",
    "\n",
    "        out = self.bn(out)\n",
    "        return l2_norm(out)\n",
    "\n",
    "##################################  Arcface head #############################################################\n",
    "\n",
    "class Arcface(Module):\n",
    "    # implementation of additive margin softmax loss in https://arxiv.org/abs/1801.05599    \n",
    "    def __init__(self, embedding_size=512, classnum=51332,  s=64., m=0.5):\n",
    "        super(Arcface, self).__init__()\n",
    "        self.classnum = classnum\n",
    "        self.kernel = Parameter(torch.Tensor(embedding_size,classnum))\n",
    "        # initial kernel\n",
    "        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
    "        self.m = m # the margin value, default is 0.5\n",
    "        self.s = s # scalar value default is 64, see normface https://arxiv.org/abs/1704.06369\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.mm = self.sin_m * m  # issue 1\n",
    "        self.threshold = math.cos(math.pi - m)\n",
    "    def forward(self, embbedings, label):\n",
    "        # weights norm\n",
    "        nB = len(embbedings)\n",
    "        kernel_norm = l2_norm(self.kernel,axis=0)\n",
    "        # cos(theta+m)\n",
    "        cos_theta = torch.mm(embbedings,kernel_norm)\n",
    "#         output = torch.mm(embbedings,kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1,1) # for numerical stability\n",
    "        cos_theta_2 = torch.pow(cos_theta, 2)\n",
    "        sin_theta_2 = 1 - cos_theta_2\n",
    "        sin_theta = torch.sqrt(sin_theta_2)\n",
    "        cos_theta_m = (cos_theta * self.cos_m - sin_theta * self.sin_m)\n",
    "        # this condition controls the theta+m should in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_theta - self.threshold\n",
    "        cond_mask = cond_v <= 0\n",
    "        keep_val = (cos_theta - self.mm) # when theta not in [0,pi], use cosface instead\n",
    "        cos_theta_m[cond_mask] = keep_val[cond_mask]\n",
    "        output = cos_theta * 1.0 # a little bit hacky way to prevent in_place operation on cos_theta\n",
    "        idx_ = torch.arange(0, nB, dtype=torch.long)\n",
    "        output[idx_, label] = cos_theta_m[idx_, label]\n",
    "        output *= self.s # scale up in order to make softmax work, first introduced in normface\n",
    "        return output\n",
    "\n",
    "##################################  Cosface head #############################################################    \n",
    "    \n",
    "class Am_softmax(Module):\n",
    "    # implementation of additive margin softmax loss in https://arxiv.org/abs/1801.05599    \n",
    "    def __init__(self,embedding_size=512,classnum=51332):\n",
    "        super(Am_softmax, self).__init__()\n",
    "        self.classnum = classnum\n",
    "        self.kernel = Parameter(torch.Tensor(embedding_size,classnum))\n",
    "        # initial kernel\n",
    "        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
    "        self.m = 0.35 # additive margin recommended by the paper\n",
    "        self.s = 30. # see normface https://arxiv.org/abs/1704.06369\n",
    "    def forward(self,embbedings,label):\n",
    "        kernel_norm = l2_norm(self.kernel,axis=0)\n",
    "        cos_theta = torch.mm(embbedings,kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1,1) # for numerical stability\n",
    "        phi = cos_theta - self.m\n",
    "        label = label.view(-1,1) #size=(B,1)\n",
    "        index = cos_theta.data * 0.0 #size=(B,Classnum)\n",
    "        index.scatter_(1,label.data.view(-1,1),1)\n",
    "        index = index.byte()\n",
    "        output = cos_theta * 1.0\n",
    "        output[index] = phi[index] #only change the correct predicted output\n",
    "        output *= self.s # scale up in order to make softmax work, first introduced in normface\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verifications.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T13:18:13.699678Z",
     "start_time": "2020-07-20T13:18:13.669631Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(embeddings, actual_issame, nrof_folds=10, pca=0):\n",
    "    # Calculate evaluation metrics\n",
    "    thresholds = np.arange(0, 4, 0.01)\n",
    "    embeddings1 = embeddings[0::2]\n",
    "    embeddings2 = embeddings[1::2]\n",
    "    tpr, fpr, accuracy, best_thresholds = calculate_roc(thresholds, embeddings1, embeddings2,\n",
    "                                       np.asarray(actual_issame), nrof_folds=nrof_folds, pca=pca)\n",
    "#     thresholds = np.arange(0, 4, 0.001)\n",
    "#     val, val_std, far = calculate_val(thresholds, embeddings1, embeddings2,\n",
    "#                                       np.asarray(actual_issame), 1e-3, nrof_folds=nrof_folds)\n",
    "#     return tpr, fpr, accuracy, best_thresholds, val, val_std, far\n",
    "    return tpr, fpr, accuracy, best_thresholds\n",
    "\n",
    "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10, pca=0):\n",
    "    assert (embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert (embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "\n",
    "    tprs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    fprs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    accuracy = np.zeros((nrof_folds))\n",
    "    best_thresholds = np.zeros((nrof_folds))\n",
    "    indices = np.arange(nrof_pairs)\n",
    "    # print('pca', pca)\n",
    "\n",
    "    if pca == 0:\n",
    "        diff = np.subtract(embeddings1, embeddings2)\n",
    "        dist = np.sum(np.square(diff), 1)\n",
    "\n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        # print('train_set', train_set)\n",
    "        # print('test_set', test_set)\n",
    "        if pca > 0:\n",
    "            print('doing pca on', fold_idx)\n",
    "            embed1_train = embeddings1[train_set]\n",
    "            embed2_train = embeddings2[train_set]\n",
    "            _embed_train = np.concatenate((embed1_train, embed2_train), axis=0)\n",
    "            # print(_embed_train.shape)\n",
    "            pca_model = PCA(n_components=pca)\n",
    "            pca_model.fit(_embed_train)\n",
    "            embed1 = pca_model.transform(embeddings1)\n",
    "            embed2 = pca_model.transform(embeddings2)\n",
    "            embed1 = sklearn.preprocessing.normalize(embed1)\n",
    "            embed2 = sklearn.preprocessing.normalize(embed2)\n",
    "            # print(embed1.shape, embed2.shape)\n",
    "            diff = np.subtract(embed1, embed2)\n",
    "            dist = np.sum(np.square(diff), 1)\n",
    "\n",
    "        # Find the best threshold for the fold\n",
    "        acc_train = np.zeros((nrof_thresholds))\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
    "        best_threshold_index = np.argmax(acc_train)\n",
    "#         print('best_threshold_index', best_threshold_index, acc_train[best_threshold_index])\n",
    "        best_thresholds[fold_idx] = thresholds[best_threshold_index]\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            tprs[fold_idx, threshold_idx], fprs[fold_idx, threshold_idx], _ = calculate_accuracy(threshold,\n",
    "                                                                                                 dist[test_set],\n",
    "                                                                                                 actual_issame[\n",
    "                                                                                                     test_set])\n",
    "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set],\n",
    "                                                      actual_issame[test_set])\n",
    "\n",
    "    tpr = np.mean(tprs, 0)\n",
    "    fpr = np.mean(fprs, 0)\n",
    "    return tpr, fpr, accuracy, best_thresholds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T13:18:14.171028Z",
     "start_time": "2020-07-20T13:18:14.055033Z"
    }
   },
   "outputs": [],
   "source": [
    "class face_learner(object):\n",
    "    def __init__(self, conf, inference=False):\n",
    "        print(conf)\n",
    "        if conf.use_mobilfacenet:\n",
    "            self.model = MobileFaceNet(conf.embedding_size).to(conf.device)\n",
    "            print('MobileFaceNet model generated')\n",
    "        else:\n",
    "            self.model = Backbone(conf.net_depth, conf.drop_ratio, conf.net_mode).to(conf.device)\n",
    "            print('{}_{} model generated'.format(conf.net_mode, conf.net_depth))\n",
    "        \n",
    "        \n",
    "        if not inference:\n",
    "            self.milestones = conf.milestones\n",
    "            self.loader, self.class_num = get_train_loader(conf)   \n",
    "            print('self.loader',self.loader)\n",
    "\n",
    "            self.writer = SummaryWriter(conf.log_path)\n",
    "            self.step = 0\n",
    "            self.head = Arcface(embedding_size=conf.embedding_size, classnum=self.class_num).to(conf.device)\n",
    "\n",
    "            print('two model heads generated')\n",
    "\n",
    "            paras_only_bn, paras_wo_bn = separate_bn_paras(self.model)\n",
    "        \n",
    "            \n",
    "            if conf.use_mobilfacenet:\n",
    "                self.optimizer = optim.SGD([\n",
    "                                    {'params': paras_wo_bn[:-1], 'weight_decay': 4e-5},\n",
    "                                    {'params': [paras_wo_bn[-1]] + [self.head.kernel], 'weight_decay': 4e-4},\n",
    "                                    {'params': paras_only_bn}\n",
    "                                ], lr = conf.lr, momentum = conf.momentum)\n",
    "            else:\n",
    "                self.optimizer = optim.SGD([\n",
    "                                    {'params': paras_wo_bn + [self.head.kernel], 'weight_decay': 5e-4},\n",
    "#                                     {'params': paras_only_bn}\n",
    "                                ], lr = conf.lr, momentum = conf.momentum)\n",
    "            print(self.optimizer)\n",
    "#             self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, patience=40, verbose=True)\n",
    "\n",
    "            print('optimizers generated')    \n",
    "#             self.board_loss_every = len(self.loader)//100\n",
    "#             self.evaluate_every = len(self.loader)//10\n",
    "#             self.save_every = len(self.loader)//5\n",
    "           \n",
    "            self.board_loss_every = len(self.loader)\n",
    "            self.evaluate_every = len(self.loader)\n",
    "            self.save_every = len(self.loader)\n",
    "#             self.agedb_30, self.cfp_fp, self.lfw, self.agedb_30_issame, self.cfp_fp_issame, self.lfw_issame = get_val_data(self.loader.dataset.root.parent)\n",
    "            self.lfw, self.lfw_issame = get_val_data(conf.smallvgg_folder)\n",
    "\n",
    "#         else:\n",
    "            self.threshold = conf.threshold\n",
    "    \n",
    "    def save_state(self, conf, accuracy, to_save_folder=False, extra=None, model_only=False):\n",
    "        if to_save_folder:\n",
    "            save_path = conf.save_path\n",
    "        else:\n",
    "            save_path = conf.model_path\n",
    "        torch.save(\n",
    "            self.model.state_dict(), save_path /\n",
    "            ('model_{}_accuracy:{}_step:{}_{}.pth'.format(get_time(), accuracy, self.step, extra)))\n",
    "        if not model_only:\n",
    "            torch.save(\n",
    "                self.head.state_dict(), save_path /\n",
    "                ('head_{}_accuracy:{}_step:{}_{}.pth'.format(get_time(), accuracy, self.step, extra)))\n",
    "            torch.save(\n",
    "                self.optimizer.state_dict(), save_path /\n",
    "                ('optimizer_{}_accuracy:{}_step:{}_{}.pth'.format(get_time(), accuracy, self.step, extra)))\n",
    "    \n",
    "    def load_state(self, conf, fixed_str, from_save_folder=False, model_only=False):\n",
    "        if from_save_folder:\n",
    "            save_path = conf.save_path\n",
    "        else:\n",
    "            save_path = conf.model_path            \n",
    "        self.model.load_state_dict(torch.load(save_path/'model_{}'.format(fixed_str)))\n",
    "        if not model_only:\n",
    "            self.head.load_state_dict(torch.load(save_path/'head_{}'.format(fixed_str)))\n",
    "            self.optimizer.load_state_dict(torch.load(save_path/'optimizer_{}'.format(fixed_str)))\n",
    "        \n",
    "    def board_val(self, db_name, accuracy, best_threshold, roc_curve_tensor):\n",
    "        self.writer.add_scalar('{}_accuracy'.format(db_name), accuracy, self.step)\n",
    "        self.writer.add_scalar('{}_best_threshold'.format(db_name), best_threshold, self.step)\n",
    "        self.writer.add_image('{}_roc_curve'.format(db_name), roc_curve_tensor, self.step)\n",
    "#         self.writer.add_scalar('{}_val:true accept ratio'.format(db_name), val, self.step)\n",
    "#         self.writer.add_scalar('{}_val_std'.format(db_name), val_std, self.step)\n",
    "#         self.writer.add_scalar('{}_far:False Acceptance Ratio'.format(db_name), far, self.step)\n",
    "        \n",
    "    def evaluate(self, conf, carray, issame, nrof_folds = 5, tta = False):\n",
    "        self.model.eval()\n",
    "        idx = 0\n",
    "        embeddings = np.zeros([len(carray), conf.embedding_size])\n",
    "        with torch.no_grad():\n",
    "            while idx + conf.batch_size <= len(carray):\n",
    "                batch = torch.tensor(carray[idx:idx + conf.batch_size])\n",
    "                if tta:\n",
    "                    fliped = hflip_batch(batch)\n",
    "                    emb_batch = self.model(batch.to(conf.device)) + self.model(fliped.to(conf.device))\n",
    "                    embeddings[idx:idx + conf.batch_size] = l2_norm(emb_batch)\n",
    "                else:\n",
    "                    embeddings[idx:idx + conf.batch_size] = self.model(batch.to(conf.device)).cpu()\n",
    "                idx += conf.batch_size\n",
    "            if idx < len(carray):\n",
    "                batch = torch.tensor(carray[idx:])            \n",
    "                if tta:\n",
    "                    fliped = hflip_batch(batch)\n",
    "                    emb_batch = self.model(batch.to(conf.device)) + self.model(fliped.to(conf.device))\n",
    "                    embeddings[idx:] = l2_norm(emb_batch)\n",
    "                else:\n",
    "                    embeddings[idx:] = self.model(batch.to(conf.device)).cpu()\n",
    "        tpr, fpr, accuracy, best_thresholds = evaluate(embeddings, issame, nrof_folds)\n",
    "        buf = gen_plot(fpr, tpr)\n",
    "        roc_curve = Image.open(buf)\n",
    "        roc_curve_tensor = trans.ToTensor()(roc_curve)\n",
    "        return accuracy.mean(), best_thresholds.mean(), roc_curve_tensor\n",
    "    \n",
    "    def find_lr(self,\n",
    "                conf,\n",
    "                init_value=1e-8,\n",
    "                final_value=10.,\n",
    "                beta=0.98,\n",
    "                bloding_scale=3.,\n",
    "                num=None):\n",
    "        if not num:\n",
    "            num = len(self.loader)\n",
    "        mult = (final_value / init_value)**(1 / num)\n",
    "        lr = init_value\n",
    "        for params in self.optimizer.param_groups:\n",
    "            params['lr'] = lr\n",
    "        self.model.train()\n",
    "        avg_loss = 0.\n",
    "        best_loss = 0.\n",
    "        batch_num = 0\n",
    "        losses = []\n",
    "        log_lrs = []\n",
    "        for i, (imgs, labels) in tqdm(enumerate(self.loader), total=num):\n",
    "\n",
    "            imgs = imgs.to(conf.device)\n",
    "            labels = labels.to(conf.device)\n",
    "            batch_num += 1          \n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            embeddings = self.model(imgs)\n",
    "            thetas = self.head(embeddings, labels)\n",
    "            loss = conf.ce_loss(thetas, labels)          \n",
    "          \n",
    "            #Compute the smoothed loss\n",
    "            avg_loss = beta * avg_loss + (1 - beta) * loss.item()\n",
    "            self.writer.add_scalar('avg_loss', avg_loss, batch_num)\n",
    "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "            self.writer.add_scalar('smoothed_loss', smoothed_loss,batch_num)\n",
    "            #Stop if the loss is exploding\n",
    "            if batch_num > 1 and smoothed_loss > bloding_scale * best_loss:\n",
    "                print('exited with best_loss at {}'.format(best_loss))\n",
    "                plt.plot(log_lrs[10:-5], losses[10:-5])\n",
    "                return log_lrs, losses\n",
    "            #Record the best loss\n",
    "            if smoothed_loss < best_loss or batch_num == 1:\n",
    "                best_loss = smoothed_loss\n",
    "            #Store the values\n",
    "            losses.append(smoothed_loss)\n",
    "            log_lrs.append(math.log10(lr))\n",
    "            self.writer.add_scalar('log_lr', math.log10(lr), batch_num)\n",
    "            #Do the SGD step\n",
    "            #Update the lr for the next step\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            lr *= mult\n",
    "            for params in self.optimizer.param_groups:\n",
    "                params['lr'] = lr\n",
    "            if batch_num > num:\n",
    "                plt.plot(log_lrs[10:-5], losses[10:-5])\n",
    "                return log_lrs, losses    \n",
    "\n",
    "    def train(self, conf, epochs):\n",
    "        self.model.train()\n",
    "        \n",
    "        running_loss = 0.            \n",
    "        for e in range(epochs):\n",
    "            print('epoch {} started'.format(e))\n",
    "            \n",
    "            # schdule_lr: lr을 1/10으로 나누기\n",
    "            if e == self.milestones[0]:\n",
    "                self.schedule_lr()\n",
    "            if e == self.milestones[1]:\n",
    "                self.schedule_lr()      \n",
    "            if e == self.milestones[2]:\n",
    "                self.schedule_lr()    \n",
    "                \n",
    "            for imgs, labels in tqdm(iter(self.loader)):\n",
    "                imgs = imgs.to(conf.device)\n",
    "                labels = labels.to(conf.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                embeddings = self.model(imgs)\n",
    "                thetas = self.head(embeddings, labels)\n",
    "                loss = conf.ce_loss(thetas, labels)\n",
    "                loss.backward()\n",
    "                running_loss += loss.item()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                print('self.board_loss_every',self.board_loss_every)\n",
    "                if self.step % self.board_loss_every == 0 and self.step != 0:\n",
    "                    loss_board = running_loss / self.board_loss_every\n",
    "                    self.writer.add_scalar('train_loss', loss_board, self.step)\n",
    "                    running_loss = 0.\n",
    "                \n",
    "                if self.step % self.evaluate_every == 0 and self.step != 0:\n",
    "#                     accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.agedb_30, self.agedb_30_issame)\n",
    "#                     self.board_val('agedb_30', accuracy, best_threshold, roc_curve_tensor)\n",
    "                    accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.lfw, self.lfw_issame)\n",
    "                    self.board_val('lfw', accuracy, best_threshold, roc_curve_tensor)\n",
    "#                     accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.cfp_fp, self.cfp_fp_issame)\n",
    "#                     self.board_val('cfp_fp', accuracy, best_threshold, roc_curve_tensor)\n",
    "                    self.model.train()\n",
    "                if self.step % self.save_every == 0 and self.step != 0:\n",
    "                    self.save_state(conf, accuracy)\n",
    "                    \n",
    "                self.step += 1\n",
    "                \n",
    "        self.save_state(conf, accuracy, to_save_folder=True, extra='final')\n",
    "\n",
    "    def schedule_lr(self):\n",
    "        print('self.optimizer.param_groups',self.optimizer.param_groups)\n",
    "        for params in self.optimizer.param_groups:                 \n",
    "            params['lr'] /= 10\n",
    "        print(self.optimizer)\n",
    "    \n",
    "    def infer(self, conf, faces, target_embs, tta=False):\n",
    "        '''\n",
    "        faces : list of PIL Image\n",
    "        target_embs : [n, 512] computed embeddings of faces in facebank\n",
    "        names : recorded names of faces in facebank\n",
    "        tta : test time augmentation (hfilp, that's all)\n",
    "        '''\n",
    "        embs = []\n",
    "        for img in faces:\n",
    "            if tta:\n",
    "                mirror = trans.functional.hflip(img)\n",
    "                emb = self.model(conf.test_transform(img).to(conf.device).unsqueeze(0))\n",
    "                emb_mirror = self.model(conf.test_transform(mirror).to(conf.device).unsqueeze(0))\n",
    "                embs.append(l2_norm(emb + emb_mirror))\n",
    "            else:                        \n",
    "                embs.append(self.model(conf.test_transform(img).to(conf.device).unsqueeze(0)))\n",
    "        source_embs = torch.cat(embs)\n",
    "        \n",
    "        diff = source_embs.unsqueeze(-1) - target_embs.transpose(1,0).unsqueeze(0)\n",
    "        dist = torch.sum(torch.pow(diff, 2), dim=1)\n",
    "        minimum, min_idx = torch.min(dist, dim=1)\n",
    "        min_idx[minimum > self.threshold] = -1 # if no match, set idx to -1\n",
    "        return min_idx, minimum               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 적인 변수들: config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T13:52:19.976039Z",
     "start_time": "2020-07-20T13:52:19.955035Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_config(training = True):\n",
    "    conf = edict()\n",
    "    conf.data_path = Path('../data')\n",
    "    conf.work_path = Path('./work_space/')\n",
    "    conf.model_path = conf.work_path/'models'\n",
    "    conf.log_path = conf.work_path/'log'\n",
    "    conf.save_path = conf.work_path/'save'\n",
    "    conf.input_size = [112,112]\n",
    "    conf.embedding_size = 512\n",
    "    conf.use_mobilfacenet = False\n",
    "    conf.net_depth = 50\n",
    "    conf.drop_ratio = 0.6\n",
    "    conf.net_mode = 'ir_se' # or 'ir'\n",
    "    conf.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    conf.test_transform = trans.Compose([\n",
    "                    trans.ToTensor(),\n",
    "                    trans.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                ])\n",
    "    conf.data_mode = 'emore'\n",
    "    conf.smallvgg_folder = conf.data_path/'small_vgg'\n",
    "    conf.vgg_folder = conf.data_path/'faces_vgg2_112x112'\n",
    "#     conf.ms1m_folder = conf.data_path/'faces_ms1m_112x112'\n",
    "#     conf.emore_folder = conf.data_path/'faces_emore'\n",
    "    conf.batch_size = 100 # irse net depth 50 \n",
    "#   conf.batch_size = 200 # mobilefacenet\n",
    "    conf.batch_size = 32 # small_vgg\n",
    "\n",
    "#--------------------Training Config ------------------------    \n",
    "    if training:        \n",
    "        conf.log_path = conf.work_path/'log'\n",
    "        conf.save_path = conf.work_path/'save'\n",
    "    #     conf.weight_decay = 5e-4\n",
    "        conf.lr = 1e-3\n",
    "        conf.milestones = [12,15,18]\n",
    "        conf.momentum = 0.9\n",
    "        conf.pin_memory = True\n",
    "#         conf.num_workers = 4 # when batchsize is 200\n",
    "        conf.num_workers = 3\n",
    "        conf.ce_loss = CrossEntropyLoss()    \n",
    "        conf.threshold = 1.5\n",
    "#--------------------Inference Config ------------------------\n",
    "    else:\n",
    "        conf.facebank_path = conf.data_path/'facebank'\n",
    "        conf.threshold = 1.5\n",
    "        conf.face_limit = 10 \n",
    "        #when inference, at maximum detect 10 faces in one image, my laptop is slow\n",
    "        conf.min_face_size = 30 \n",
    "        # the larger this value, the faster deduction, comes with tradeoff in small faces\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:14:37.008865Z",
     "start_time": "2020-07-20T14:14:36.858868Z"
    }
   },
   "outputs": [],
   "source": [
    "args = edict()\n",
    "\n",
    "args.epochs =20\n",
    "args.net_mode = 'ir_se'  #\"which network, [ir, ir_se, mobilefacenet]\"\n",
    "args.net_depth = 50 # \"how many layers [50,100,152]\"\n",
    "args.lr = 1e-3\n",
    "args.batch_size = 32\n",
    "args.num_workers = 3\n",
    "args.data_mode = 'small_vgg' # use which database, [vgg, ms1m, emore, concat]\"\n",
    "\n",
    "conf = get_config()\n",
    "\n",
    "if args.net_mode == 'mobilefacenet':\n",
    "        conf.use_mobilfacenet = True\n",
    "else:\n",
    "    conf.net_mode = args.net_mode\n",
    "    conf.net_depth = args.net_depth    \n",
    "\n",
    "    \n",
    "conf.lr = args.lr\n",
    "conf.batch_size = args.batch_size\n",
    "conf.num_workers = args.num_workers\n",
    "conf.data_mode = args.data_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:14:38.911919Z",
     "start_time": "2020-07-20T14:14:37.754920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'small_vgg', 'smallvgg_folder': WindowsPath('../data/small_vgg'), 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'batch_size': 32, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss(), 'threshold': 1.5}\n",
      "ir_se_50 model generated\n",
      "class_num 3\n",
      "self.loader <torch.utils.data.dataloader.DataLoader object at 0x000002108C0DC708>\n",
      "two model heads generated\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "optimizers generated\n"
     ]
    }
   ],
   "source": [
    "learner = face_learner(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:14:55.018916Z",
     "start_time": "2020-07-20T14:14:54.772916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Backbone(\n",
       "  (input_layer): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): PReLU(num_parameters=64)\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.6, inplace=False)\n",
       "    (2): Flatten()\n",
       "    (3): Linear(in_features=25088, out_features=512, bias=True)\n",
       "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (0): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=64)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=64)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=64)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): bottleneck_IR_SE(\n",
       "      (shortcut_layer): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): bottleneck_IR_SE(\n",
       "      (shortcut_layer): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (17): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (19): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (20): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (21): bottleneck_IR_SE(\n",
       "      (shortcut_layer): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=512)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (22): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=512)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (23): bottleneck_IR_SE(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=512)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:15:28.214916Z",
     "start_time": "2020-07-20T14:14:56.436927Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/19 [00:24<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-b70990faebae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-89-04cff8b716df>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, conf, epochs)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mthetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mce_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m                 \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.train(conf, args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learner.train분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:18:58.954169Z",
     "start_time": "2020-07-20T14:18:58.948168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'small_vgg', 'smallvgg_folder': WindowsPath('../data/small_vgg'), 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'batch_size': 32, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss(), 'threshold': 1.5}\n"
     ]
    }
   ],
   "source": [
    "inference=False\n",
    "step =0\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:19:00.657753Z",
     "start_time": "2020-07-20T14:19:00.289721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_se_50 model generated\n"
     ]
    }
   ],
   "source": [
    "if conf.use_mobilfacenet:\n",
    "    model = MobileFaceNet(conf.embedding_size).to(conf.device)\n",
    "    print('MobileFaceNet model generated')\n",
    "else:\n",
    "    model = Backbone(conf.net_depth, conf.drop_ratio, conf.net_mode).to(conf.device)\n",
    "    print('{}_{} model generated'.format(conf.net_mode, conf.net_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:19:02.018720Z",
     "start_time": "2020-07-20T14:19:01.993761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_num 3\n",
      "loader <torch.utils.data.dataloader.DataLoader object at 0x000002108AB45508>\n",
      "two model heads generated\n"
     ]
    }
   ],
   "source": [
    "if not inference:\n",
    "    milestones = conf.milestones\n",
    "    loader, class_num = get_train_loader(conf)   \n",
    "    print('loader',loader)\n",
    "\n",
    "    writer = SummaryWriter(conf.log_path)\n",
    "    step = 0\n",
    "    head = Arcface(embedding_size=conf.embedding_size, classnum=class_num).to(conf.device)\n",
    "\n",
    "    print('two model heads generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:19:03.059721Z",
     "start_time": "2020-07-20T14:19:03.042724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 635\n"
     ]
    }
   ],
   "source": [
    "paras_only_bn, paras_wo_bn = separate_bn_paras(model)\n",
    "print(len(paras_only_bn), len(paras_wo_bn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:19:04.073720Z",
     "start_time": "2020-07-20T14:19:04.040756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "optimizers generated\n"
     ]
    }
   ],
   "source": [
    "if conf.use_mobilfacenet:\n",
    "    optimizer = optim.SGD([\n",
    "                        {'params': paras_wo_bn[:-1], 'weight_decay': 4e-5},\n",
    "                        {'params': [paras_wo_bn[-1]] + [head.kernel], 'weight_decay': 4e-4},\n",
    "                        {'params': paras_only_bn}\n",
    "                    ], lr = conf.lr, momentum = conf.momentum)\n",
    "else:\n",
    "    optimizer = optim.SGD([\n",
    "                        {'params': paras_wo_bn + [head.kernel], 'weight_decay': 5e-4},\n",
    "#                                     {'params': paras_only_bn}\n",
    "                    ], lr = conf.lr, momentum = conf.momentum)\n",
    "print(optimizer)\n",
    "#             self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, patience=40, verbose=True)\n",
    "\n",
    "print('optimizers generated')    \n",
    "#             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:19:05.184717Z",
     "start_time": "2020-07-20T14:19:05.169731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "(12000, 3, 112, 112) 6000\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "print(len(loader))  # 데이터를 32개씩 7번 갖고오기\n",
    "# self.board_loss_every = len(self.loader)//100\n",
    "# self.evaluate_every = len(self.loader)//10\n",
    "# self.save_every = len(self.loader)//5\n",
    "board_loss_every = len(loader)\n",
    "evaluate_every = len(loader)\n",
    "save_every = len(loader)\n",
    "#             self.agedb_30, self.cfp_fp, self.lfw, self.agedb_30_issame, self.cfp_fp_issame, self.lfw_issame = get_val_data(self.loader.dataset.root.parent)\n",
    "lfw, lfw_issame = get_val_data(conf.smallvgg_folder)\n",
    "print(lfw.shape, len(lfw_issame))\n",
    "\n",
    "#         else:\n",
    "threshold = conf.threshold\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T14:19:06.085726Z",
     "start_time": "2020-07-20T14:19:06.072757Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_state(conf, accuracy, to_save_folder=False, extra=None, model_only=False):\n",
    "    if to_save_folder:\n",
    "        save_path = conf.save_path\n",
    "    else:\n",
    "        save_path = conf.model_path\n",
    "    torch.save(\n",
    "        model.state_dict(), save_path('model_{}_accuracy:{}_step:{}_{}.pth'.format(get_time(), accuracy, step, extra)))\n",
    "    if not model_only:\n",
    "        torch.save(\n",
    "            head.state_dict(), save_path('head_{}_accuracy:{}_step:{}_{}.pth'.format(get_time(), accuracy, step, extra)))\n",
    "        torch.save(\n",
    "            optimizer.state_dict(), save_path('optimizer_{}_accuracy:{}_step:{}_{}.pth'.format(get_time(), accuracy, step, extra)))\n",
    "\n",
    "def load_state(conf, fixed_str, from_save_folder=False, model_only=False):\n",
    "    if from_save_folder:\n",
    "        save_path = conf.save_path\n",
    "    else:\n",
    "        save_path = conf.model_path            \n",
    "    model.load_state_dict(torch.load(save_path/'model_{}'.format(fixed_str)))\n",
    "    if not model_only:\n",
    "        head.load_state_dict(torch.load(save_path/'head_{}'.format(fixed_str)))\n",
    "        optimizer.load_state_dict(torch.load(save_path/'optimizer_{}'.format(fixed_str)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:42:04.822921Z",
     "start_time": "2020-07-21T01:42:04.746915Z"
    }
   },
   "outputs": [],
   "source": [
    "def board_val(db_name, accuracy, best_threshold, roc_curve_tensor, step):\n",
    "    \"\"\"log 남기기\"\"\"\n",
    "    writer.add_scalar('{}_accuracy'.format(db_name), accuracy, step)\n",
    "    writer.add_scalar('{}_best_threshold'.format(db_name), best_threshold, step)\n",
    "    writer.add_image('{}_roc_curve'.format(db_name), roc_curve_tensor, step)\n",
    "#         self.writer.add_scalar('{}_val:true accept ratio'.format(db_name), val, self.step)\n",
    "#         self.writer.add_scalar('{}_val_std'.format(db_name), val_std, self.step)\n",
    "#         self.writer.add_scalar('{}_far:False Acceptance Ratio'.format(db_name), far, self.step)\n",
    "\n",
    "def evaluate(conf, carray, issame, nrof_folds = 5, tta = False):\n",
    "    model.eval()\n",
    "    idx = 0\n",
    "    print('conf', conf)\n",
    "    embeddings = np.zeros([len(carray), conf.embedding_size])\n",
    "    with torch.no_grad():\n",
    "        while idx + conf.batch_size <= len(carray):\n",
    "            batch = torch.tensor(carray[idx:idx + conf.batch_size])\n",
    "            \n",
    "             # tta : test time augmentation (hfilp, that's all)\n",
    "            if tta:\n",
    "                fliped = hflip_batch(batch)\n",
    "                emb_batch = model(batch.to(conf.device)) + model(fliped.to(conf.device))\n",
    "                embeddings[idx:idx + conf.batch_size] = l2_norm(emb_batch)\n",
    "            else:\n",
    "                embeddings[idx:idx + conf.batch_size] = model(batch.to(conf.device)).cpu()\n",
    "            idx += conf.batch_size\n",
    "        if idx < len(carray):\n",
    "            batch = torch.tensor(carray[idx:])            \n",
    "            if tta:\n",
    "                fliped = hflip_batch(batch)\n",
    "                emb_batch = model(batch.to(conf.device)) + model(fliped.to(conf.device))\n",
    "                embeddings[idx:] = l2_norm(emb_batch)\n",
    "            else:\n",
    "                embeddings[idx:] = model(batch.to(conf.device)).cpu()\n",
    "    tpr, fpr, accuracy, best_thresholds = evaluate(embeddings, issame, nrof_folds)\n",
    "    buf = gen_plot(fpr, tpr)\n",
    "    roc_curve = Image.open(buf)\n",
    "    roc_curve_tensor = trans.ToTensor()(roc_curve)\n",
    "    return accuracy.mean(), best_thresholds.mean(), roc_curve_tensor\n",
    "\n",
    "def find_lr(\n",
    "            conf,\n",
    "            init_value=1e-8,\n",
    "            final_value=10.,\n",
    "            beta=0.98,\n",
    "            bloding_scale=3.,\n",
    "            num=None):\n",
    "    if not num:\n",
    "        num = len(self.loader)\n",
    "    mult = (final_value / init_value)**(1 / num)\n",
    "    lr = init_value\n",
    "    for params in optimizer.param_groups:\n",
    "        params['lr'] = lr\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    for i, (imgs, labels) in tqdm(enumerate(loader), total=num):\n",
    "\n",
    "        imgs = imgs.to(conf.device)\n",
    "        labels = labels.to(conf.device)\n",
    "        batch_num += 1          \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        embeddings = model(imgs)\n",
    "        thetas = head(embeddings, labels)\n",
    "        loss = conf.ce_loss(thetas, labels)          \n",
    "\n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1 - beta) * loss.item()\n",
    "        writer.add_scalar('avg_loss', avg_loss, batch_num)\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        writer.add_scalar('smoothed_loss', smoothed_loss,batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > bloding_scale * best_loss:\n",
    "            print('exited with best_loss at {}'.format(best_loss))\n",
    "            plt.plot(log_lrs[10:-5], losses[10:-5])\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num == 1:\n",
    "            best_loss = smoothed_loss\n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        writer.add_scalar('log_lr', math.log10(lr), batch_num)\n",
    "        #Do the SGD step\n",
    "        #Update the lr for the next step\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lr *= mult\n",
    "        for params in optimizer.param_groups:\n",
    "            params['lr'] = lr\n",
    "        if batch_num > num:\n",
    "            plt.plot(log_lrs[10:-5], losses[10:-5])\n",
    "            return log_lrs, losses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:42:27.128936Z",
     "start_time": "2020-07-21T01:42:27.085938Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def schedule_lr():\n",
    "    print('self.optimizer.param_groups',optimizer.param_groups)\n",
    "    for params in optimizer.param_groups:                 \n",
    "        params['lr'] /= 10\n",
    "    print(optimizer)\n",
    "\n",
    "def infer( conf, faces, target_embs, tta=False):\n",
    "    '''\n",
    "    faces : list of PIL Image\n",
    "    target_embs : [n, 512] computed embeddings of faces in facebank\n",
    "    names : recorded names of faces in facebank\n",
    "    tta : test time augmentation (hfilp, that's all)\n",
    "    '''\n",
    "    embs = []\n",
    "    for img in faces:\n",
    "        if tta:\n",
    "            mirror = trans.functional.hflip(img)\n",
    "            emb = model(conf.test_transform(img).to(conf.device).unsqueeze(0))\n",
    "            emb_mirror = self.model(conf.test_transform(mirror).to(conf.device).unsqueeze(0))\n",
    "            embs.append(l2_norm(emb + emb_mirror))\n",
    "        else:                        \n",
    "            embs.append(model(conf.test_transform(img).to(conf.device).unsqueeze(0)))\n",
    "    source_embs = torch.cat(embs)\n",
    "\n",
    "    diff = source_embs.unsqueeze(-1) - target_embs.transpose(1,0).unsqueeze(0)\n",
    "    dist = torch.sum(torch.pow(diff, 2), dim=1)\n",
    "    minimum, min_idx = torch.min(dist, dim=1)\n",
    "    min_idx[minimum > self.threshold] = -1 # if no match, set idx to -1\n",
    "    return min_idx, minimum               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T02:35:54.475515Z",
     "start_time": "2020-07-21T01:42:27.958938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1conf {'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'small_vgg', 'smallvgg_folder': WindowsPath('../data/small_vgg'), 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'batch_size': 32, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss(), 'threshold': 1.5}\n",
      "epoch 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(imgs) 32\n",
      "labels[0] tensor(0)\n",
      "embeddings.shape torch.Size([32, 512])\n",
      "2conf {'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'small_vgg', 'smallvgg_folder': WindowsPath('../data/small_vgg'), 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'batch_size': 32, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss(), 'threshold': 1.5}\n",
      "self.board_loss_every 19\n",
      "3conf {'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'small_vgg', 'smallvgg_folder': WindowsPath('../data/small_vgg'), 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'batch_size': 32, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss(), 'threshold': 1.5}\n",
      "conf {'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'small_vgg', 'smallvgg_folder': WindowsPath('../data/small_vgg'), 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'batch_size': 32, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss(), 'threshold': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/19 [53:21<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf [[-0.03640028 -0.01016091 -0.05237515 ...  0.00317176  0.03885107\n",
      "   0.0435136 ]\n",
      " [-0.0468617  -0.02259325 -0.06367933 ... -0.02695115  0.04540954\n",
      "   0.04897029]\n",
      " [-0.06503185 -0.02208477 -0.04285299 ... -0.00794406  0.08428808\n",
      "   0.01871988]\n",
      " ...\n",
      " [-0.04949481 -0.00074774 -0.05230327 ... -0.00606669  0.07469331\n",
      "   0.0344974 ]\n",
      " [-0.06921243 -0.02592494 -0.05089281 ...  0.00329973  0.08979934\n",
      "   0.02926286]\n",
      " [ 0.00928768  0.02667079 -0.02893333 ... -0.02688265  0.0084578\n",
      "   0.04681375]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'embedding_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-0920af486c9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-173-412884ab60eb>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(conf, epochs)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#                     self.board_val('agedb_30', accuracy, best_threshold, roc_curve_tensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'3conf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_curve_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrof_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mboard_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lfw'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_curve_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-172-d2ffcdd2a659>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(conf, carray, issame, nrof_folds, tta)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_thresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrof_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mroc_curve\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-172-d2ffcdd2a659>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(conf, carray, issame, nrof_folds, tta)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'conf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'embedding_size'"
     ]
    }
   ],
   "source": [
    "train(conf, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T03:05:32.332101Z",
     "start_time": "2020-07-21T03:05:31.813131Z"
    }
   },
   "outputs": [],
   "source": [
    "model =  Backbone(conf.net_depth, conf.drop_ratio, conf.net_mode).to(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T03:53:33.493619Z",
     "start_time": "2020-07-21T03:05:34.778169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1conf {'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'small_vgg', 'smallvgg_folder': WindowsPath('../data/small_vgg'), 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'batch_size': 32, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss(), 'threshold': 1.5}\n",
      "epoch 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(imgs) 32\n",
      "labels[0] tensor(0)\n",
      "embeddings.shape torch.Size([32, 512])\n",
      "2conf {'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'small_vgg', 'smallvgg_folder': WindowsPath('../data/small_vgg'), 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'batch_size': 32, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss(), 'threshold': 1.5}\n",
      "self.board_loss_every 19\n",
      "3conf {'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'small_vgg', 'smallvgg_folder': WindowsPath('../data/small_vgg'), 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'batch_size': 32, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss(), 'threshold': 1.5}\n",
      "conf {'data_path': WindowsPath('../data'), 'work_path': WindowsPath('work_space'), 'model_path': WindowsPath('work_space/models'), 'log_path': WindowsPath('work_space/log'), 'save_path': WindowsPath('work_space/save'), 'input_size': [112, 112], 'embedding_size': 512, 'use_mobilfacenet': False, 'net_depth': 50, 'drop_ratio': 0.6, 'net_mode': 'ir_se', 'device': device(type='cpu'), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "), 'data_mode': 'small_vgg', 'smallvgg_folder': WindowsPath('../data/small_vgg'), 'vgg_folder': WindowsPath('../data/faces_vgg2_112x112'), 'batch_size': 32, 'lr': 0.001, 'milestones': [12, 15, 18], 'momentum': 0.9, 'pin_memory': True, 'num_workers': 3, 'ce_loss': CrossEntropyLoss(), 'threshold': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/19 [47:54<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf [[ 0.01842494  0.00926026 -0.00363952 ... -0.01706075  0.08290605\n",
      "  -0.03206192]\n",
      " [ 0.0170774   0.03319558  0.02032072 ...  0.00922361  0.07476907\n",
      "  -0.05107157]\n",
      " [ 0.02838515 -0.00971706 -0.0276707  ...  0.00019179  0.0553182\n",
      "   0.00080437]\n",
      " ...\n",
      " [-0.00421557 -0.00432005 -0.03186348 ... -0.01083308  0.00673183\n",
      "   0.05190581]\n",
      " [ 0.02441553  0.02019737 -0.01692394 ... -0.00654758  0.0326555\n",
      "   0.00741459]\n",
      " [-0.00646763  0.02037716  0.03938152 ... -0.0383382   0.05314334\n",
      "   0.02987057]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'embedding_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-9a943826e3aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#                     self.board_val('agedb_30', accuracy, best_threshold, roc_curve_tensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'3conf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_curve_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrof_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mboard_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lfw'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_curve_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-172-d2ffcdd2a659>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(conf, carray, issame, nrof_folds, tta)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_thresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrof_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mroc_curve\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-172-d2ffcdd2a659>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(conf, carray, issame, nrof_folds, tta)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'conf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'embedding_size'"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "step = 1\n",
    "model.train()\n",
    "\n",
    "running_loss = 0.  \n",
    "print('1conf', conf)\n",
    "for e in range(epochs):\n",
    "    print('epoch {} started'.format(e))\n",
    "\n",
    "    # schdule_lr: lr을 1/10으로 나누기\n",
    "    if e == milestones[0]:\n",
    "        schedule_lr()\n",
    "    if e == milestones[1]:\n",
    "        schedule_lr()      \n",
    "    if e == milestones[2]:\n",
    "        schedule_lr()    \n",
    "\n",
    "\n",
    "    for imgs, labels in tqdm(iter(loader)):\n",
    "        imgs = imgs.to(conf.device)\n",
    "        print('len(imgs)',len(imgs))\n",
    "        labels = labels.to(conf.device)\n",
    "        print('labels[0]',labels[0])\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(imgs)\n",
    "        print('embeddings.shape',embeddings.shape)\n",
    "        thetas = head(embeddings, labels)\n",
    "        loss = conf.ce_loss(thetas, labels)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        print('2conf', conf)\n",
    "        print('self.board_loss_every',board_loss_every)\n",
    "#             if step % board_loss_every == 0 and step != 0:\n",
    "        loss_board = running_loss / board_loss_every\n",
    "        writer.add_scalar('train_loss', loss_board, step)\n",
    "        running_loss = 0.\n",
    "\n",
    "#             if step % evaluate_every == 0 and step != 0:\n",
    "#                     accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.agedb_30, self.agedb_30_issame)\n",
    "#                     self.board_val('agedb_30', accuracy, best_threshold, roc_curve_tensor)\n",
    "        print('3conf', conf)\n",
    "        accuracy, best_threshold, roc_curve_tensor = evaluate(conf, carray, issame, nrof_folds = 5, tta = False)\n",
    "\n",
    "        board_val('lfw', accuracy, best_threshold, roc_curve_tensor, step)\n",
    "#                     accuracy, best_threshold, roc_curve_tensor = self.evaluate(conf, self.cfp_fp, self.cfp_fp_issame)\n",
    "#                     self.board_val('cfp_fp', accuracy, best_threshold, roc_curve_tensor)\n",
    "        model.train()\n",
    "\n",
    "#             if step % save_every == 0 and step != 0:\n",
    "        save_state(conf, accuracy)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "save_state(conf, accuracy, to_save_folder=True, extra='final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:35:32.920327Z",
     "start_time": "2020-07-21T05:35:32.913329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86142"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400 + 85742\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T06:04:13.029322Z",
     "start_time": "2020-07-21T06:04:13.020323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5872144"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5822653 + 49491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231.094px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
