{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py(face_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:17.736781Z",
     "start_time": "2020-07-18T15:13:15.561787Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from easydict import EasyDict\n",
    "from torch import nn\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import visdom\n",
    "import time\n",
    "import logging\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import scipy.io\n",
    "import json\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mobilefacenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:22.260789Z",
     "start_time": "2020-07-18T15:13:20.965787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileFaceNet(\n",
      "  (conv1): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (prelu): PReLU(num_parameters=64)\n",
      "  )\n",
      "  (dw_conv1): ConvBlock(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (prelu): PReLU(num_parameters=64)\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=128)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=128)\n",
      "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=128)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=128)\n",
      "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=128)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=128)\n",
      "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=128)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=128)\n",
      "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=128)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=128)\n",
      "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=512)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=512)\n",
      "        (6): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): PReLU(num_parameters=256)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): PReLU(num_parameters=256)\n",
      "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): ConvBlock(\n",
      "    (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (prelu): PReLU(num_parameters=512)\n",
      "  )\n",
      "  (linear7): ConvBlock(\n",
      "    (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (linear1): ConvBlock(\n",
      "    (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128])\n"
     ]
    }
   ],
   "source": [
    "# from backbone.mobilefacenet import MobileFaceNet\n",
    "MobileFaceNet_BottleNeck_Setting = [\n",
    "    # t, c , n ,s\n",
    "    [2, 64, 5, 2],\n",
    "    [4, 128, 1, 2],\n",
    "    [2, 128, 6, 1],\n",
    "    [4, 128, 1, 2],\n",
    "    [2, 128, 2, 1]\n",
    "]\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expansion):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.connect = stride == 1 and inp == oup\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # 1*1 conv\n",
    "            nn.Conv2d(inp, inp * expansion, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(inp * expansion),\n",
    "            nn.PReLU(inp * expansion),\n",
    "\n",
    "            # 3*3 depth wise conv\n",
    "            nn.Conv2d(inp * expansion, inp * expansion, 3, stride, 1, groups=inp * expansion, bias=False),\n",
    "            nn.BatchNorm2d(inp * expansion),\n",
    "            nn.PReLU(inp * expansion),\n",
    "\n",
    "            # 1*1 conv\n",
    "            nn.Conv2d(inp * expansion, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, inp, oup, k, s, p, dw=False, linear=False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.linear = linear\n",
    "        if dw:\n",
    "            self.conv = nn.Conv2d(inp, oup, k, s, p, groups=inp, bias=False)\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(inp, oup, k, s, p, bias=False)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(oup)\n",
    "        if not linear:\n",
    "            self.prelu = nn.PReLU(oup)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.linear:\n",
    "            return x\n",
    "        else:\n",
    "            return self.prelu(x)\n",
    "\n",
    "\n",
    "class MobileFaceNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128, bottleneck_setting=MobileFaceNet_BottleNeck_Setting):\n",
    "        super(MobileFaceNet, self).__init__()\n",
    "        self.conv1 = ConvBlock(3, 64, 3, 2, 1)\n",
    "        self.dw_conv1 = ConvBlock(64, 64, 3, 1, 1, dw=True)\n",
    "\n",
    "        self.cur_channel = 64\n",
    "        block = BottleNeck\n",
    "        self.blocks = self._make_layer(block, bottleneck_setting)\n",
    "\n",
    "        self.conv2 = ConvBlock(128, 512, 1, 1, 0)\n",
    "        self.linear7 = ConvBlock(512, 512, 7, 1, 0, dw=True, linear=True)\n",
    "        self.linear1 = ConvBlock(512, feature_dim, 1, 1, 0, linear=True)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, setting):\n",
    "        layers = []\n",
    "        for t, c, n, s in setting:\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    layers.append(block(self.cur_channel, c, s, t))\n",
    "                else:\n",
    "                    layers.append(block(self.cur_channel, c, 1, t))\n",
    "                self.cur_channel = c\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dw_conv1(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.linear7(x)\n",
    "        x = self.linear1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input = torch.Tensor(2, 3, 112, 112)\n",
    "    net = MobileFaceNet()\n",
    "    print(net)\n",
    "\n",
    "    x = net(input)\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cbam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:22.377790Z",
     "start_time": "2020-07-18T15:13:22.264785Z"
    }
   },
   "outputs": [],
   "source": [
    "# from backbone.cbam import CBAMResNet\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    '''Squeeze and Excitation Module'''\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return input * x\n",
    "\n",
    "class CAModule(nn.Module):\n",
    "    '''Channel Attention Module'''\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(CAModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.shared_mlp = nn.Sequential(nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0, bias=False),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        avg_pool = self.avg_pool(x)\n",
    "        max_pool = self.max_pool(x)\n",
    "        x = self.shared_mlp(avg_pool) + self.shared_mlp(max_pool)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return input * x\n",
    "\n",
    "class SAModule(nn.Module):\n",
    "    '''Spatial Attention Module'''\n",
    "    def __init__(self):\n",
    "        super(SAModule, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        avg_c = torch.mean(x, 1, True)\n",
    "        max_c, _ = torch.max(x, 1, True)\n",
    "        x = torch.cat((avg_c, max_c), 1)\n",
    "        x = self.conv(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return input * x\n",
    "\n",
    "class BottleNeck_IR(nn.Module):\n",
    "    '''Improved Residual Bottlenecks'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel))\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_SE(nn.Module):\n",
    "    '''Improved Residual Bottlenecks with Squeeze and Excitation Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_SE, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       SEModule(out_channel, 16))\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_CAM(nn.Module):\n",
    "    '''Improved Residual Bottlenecks with Channel Attention Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_CAM, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       CAModule(out_channel, 16))\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_SAM(nn.Module):\n",
    "    '''Improved Residual Bottlenecks with Spatial Attention Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_SAM, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       SAModule())\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "class BottleNeck_IR_CBAM(nn.Module):\n",
    "    '''Improved Residual Bottleneck with Channel Attention Module and Spatial Attention Module'''\n",
    "    def __init__(self, in_channel, out_channel, stride, dim_match):\n",
    "        super(BottleNeck_IR_CBAM, self).__init__()\n",
    "        self.res_layer = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                       nn.Conv2d(in_channel, out_channel, (3, 3), 1, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       nn.PReLU(out_channel),\n",
    "                                       nn.Conv2d(out_channel, out_channel, (3, 3), stride, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(out_channel),\n",
    "                                       CAModule(out_channel, 16),\n",
    "                                       SAModule()\n",
    "                                       )\n",
    "        if dim_match:\n",
    "            self.shortcut_layer = None\n",
    "        else:\n",
    "            self.shortcut_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        if self.shortcut_layer is not None:\n",
    "            shortcut = self.shortcut_layer(x)\n",
    "\n",
    "        return shortcut + res\n",
    "\n",
    "\n",
    "filter_list = [64, 64, 128, 256, 512]\n",
    "def get_layers(num_layers):\n",
    "    if num_layers == 50:\n",
    "        return [3, 4, 14, 3]\n",
    "    elif num_layers == 100:\n",
    "        return [3, 13, 30, 3]\n",
    "    elif num_layers == 152:\n",
    "        return [3, 8, 36, 3]\n",
    "\n",
    "class CBAMResNet(nn.Module):\n",
    "    def __init__(self, num_layers, feature_dim=512, drop_ratio=0.4, mode='ir',filter_list=filter_list):\n",
    "        super(CBAMResNet, self).__init__()\n",
    "        assert num_layers in [50, 100, 152], 'num_layers should be 50, 100 or 152'\n",
    "        assert mode in ['ir', 'ir_se', 'ir_cam', 'ir_sam', 'ir_cbam'], 'mode should be ir, ir_se, ir_cam, ir_sam or ir_cbam'\n",
    "        layers = get_layers(num_layers)\n",
    "        if mode == 'ir':\n",
    "            block = BottleNeck_IR\n",
    "        elif mode == 'ir_se':\n",
    "            block = BottleNeck_IR_SE\n",
    "        elif mode == 'ir_cam':\n",
    "            block = BottleNeck_IR_CAM\n",
    "        elif mode == 'ir_sam':\n",
    "            block = BottleNeck_IR_SAM\n",
    "        elif mode == 'ir_cbam':\n",
    "            block = BottleNeck_IR_CBAM\n",
    "\n",
    "        self.input_layer = nn.Sequential(nn.Conv2d(3, 64, (3, 3), stride=1, padding=1, bias=False),\n",
    "                                         nn.BatchNorm2d(64),\n",
    "                                         nn.PReLU(64))\n",
    "        self.layer1 = self._make_layer(block, filter_list[0], filter_list[1], layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, filter_list[1], filter_list[2], layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, filter_list[2], filter_list[3], layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, filter_list[3], filter_list[4], layers[3], stride=2)\n",
    "\n",
    "        self.output_layer = nn.Sequential(nn.BatchNorm2d(512),\n",
    "                                          nn.Dropout(drop_ratio),\n",
    "                                          Flatten(),\n",
    "                                          nn.Linear(512 * 7 * 7, feature_dim),\n",
    "                                          nn.BatchNorm1d(feature_dim))\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, in_channel, out_channel, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(in_channel, out_channel, stride, False))\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channel, out_channel, 1, True))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:22.592793Z",
     "start_time": "2020-07-18T15:13:22.452784Z"
    }
   },
   "outputs": [],
   "source": [
    "# from backbone.attention import ResidualAttentionNet_56, ResidualAttentionNet_92\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.stride = stride\n",
    "\n",
    "        self.res_bottleneck = nn.Sequential(nn.BatchNorm2d(in_channel),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(in_channel, out_channel//4, 1, 1, bias=False),\n",
    "                                            nn.BatchNorm2d(out_channel//4),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(out_channel//4, out_channel//4, 3, stride, padding=1, bias=False),\n",
    "                                            nn.BatchNorm2d(out_channel//4),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(out_channel//4, out_channel, 1, 1, bias=False))\n",
    "        self.shortcut = nn.Conv2d(in_channel, out_channel, 1, stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        out = self.res_bottleneck(x)\n",
    "        if self.in_channel != self.out_channel or self.stride != 1:\n",
    "            res = self.shortcut(x)\n",
    "\n",
    "        out += res\n",
    "        return out\n",
    "\n",
    "class AttentionModule_stage1(nn.Module):\n",
    "\n",
    "    # input size is 56*56\n",
    "    def __init__(self, in_channel, out_channel, size1=(56, 56), size2=(28, 28), size3=(14, 14)):\n",
    "        super(AttentionModule_stage1, self).__init__()\n",
    "        self.share_residual_block = ResidualBlock(in_channel, out_channel)\n",
    "        self.trunk_branches = nn.Sequential(ResidualBlock(in_channel, out_channel),\n",
    "                                            ResidualBlock(in_channel, out_channel))\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.mask_block1 = ResidualBlock(in_channel, out_channel)\n",
    "        self.skip_connect1 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.mask_block2 = ResidualBlock(in_channel, out_channel)\n",
    "        self.skip_connect2 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.mpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.mask_block3 = nn.Sequential(ResidualBlock(in_channel, out_channel),\n",
    "                                         ResidualBlock(in_channel, out_channel))\n",
    "\n",
    "        self.interpolation3 = nn.UpsamplingBilinear2d(size=size3)\n",
    "        self.mask_block4 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.interpolation2 = nn.UpsamplingBilinear2d(size=size2)\n",
    "        self.mask_block5 = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "        self.mask_block6 = nn.Sequential(nn.BatchNorm2d(out_channel),\n",
    "                                         nn.ReLU(inplace=True),\n",
    "                                         nn.Conv2d(out_channel, out_channel, 1, 1, bias=False),\n",
    "                                         nn.BatchNorm2d(out_channel),\n",
    "                                         nn.ReLU(inplace=True),\n",
    "                                         nn.Conv2d(out_channel, out_channel, 1, 1, bias=False),\n",
    "                                         nn.Sigmoid())\n",
    "\n",
    "        self.last_block = ResidualBlock(in_channel, out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.share_residual_block(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "\n",
    "        out_pool1 = self.mpool1(x)\n",
    "        out_block1 = self.mask_block1(out_pool1)\n",
    "        out_skip_connect1 = self.skip_connect1(out_block1)\n",
    "\n",
    "        out_pool2 = self.mpool2(out_block1)\n",
    "        out_block2 = self.mask_block2(out_pool2)\n",
    "        out_skip_connect2 = self.skip_connect2(out_block2)\n",
    "\n",
    "        out_pool3 = self.mpool3(out_block2)\n",
    "        out_block3 = self.mask_block3(out_pool3)\n",
    "        #\n",
    "        out_inter3 = self.interpolation3(out_block3) + out_block2\n",
    "        out = out_inter3 + out_skip_connect2\n",
    "        out_block4 = self.mask_block4(out)\n",
    "\n",
    "        out_inter2 = self.interpolation2(out_block4) + out_block1\n",
    "        out = out_inter2 + out_skip_connect1\n",
    "        out_block5 = self.mask_block5(out)\n",
    "\n",
    "        out_inter1 = self.interpolation1(out_block5) + out_trunk\n",
    "        out_block6 = self.mask_block6(out_inter1)\n",
    "\n",
    "        out = (1 + out_block6) + out_trunk\n",
    "        out_last = self.last_block(out)\n",
    "\n",
    "        return out_last\n",
    "\n",
    "class AttentionModule_stage2(nn.Module):\n",
    "\n",
    "    # input image size is 28*28\n",
    "    def __init__(self, in_channels, out_channels, size1=(28, 28), size2=(14, 14)):\n",
    "        super(AttentionModule_stage2, self).__init__()\n",
    "        self.first_residual_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.trunk_branches = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "         )\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.softmax1_blocks = ResidualBlock(in_channels, out_channels)\n",
    "        self.skip1_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.softmax2_blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.interpolation2 = nn.UpsamplingBilinear2d(size=size2)\n",
    "        self.softmax3_blocks = ResidualBlock(in_channels, out_channels)\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "        self.softmax4_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.last_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_residual_blocks(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "        out_mpool1 = self.mpool1(x)\n",
    "        out_softmax1 = self.softmax1_blocks(out_mpool1)\n",
    "        out_skip1_connection = self.skip1_connection_residual_block(out_softmax1)\n",
    "\n",
    "        out_mpool2 = self.mpool2(out_softmax1)\n",
    "        out_softmax2 = self.softmax2_blocks(out_mpool2)\n",
    "\n",
    "        out_interp2 = self.interpolation2(out_softmax2) + out_softmax1\n",
    "        out = out_interp2 + out_skip1_connection\n",
    "\n",
    "        out_softmax3 = self.softmax3_blocks(out)\n",
    "        out_interp1 = self.interpolation1(out_softmax3) + out_trunk\n",
    "        out_softmax4 = self.softmax4_blocks(out_interp1)\n",
    "        out = (1 + out_softmax4) * out_trunk\n",
    "        out_last = self.last_blocks(out)\n",
    "\n",
    "        return out_last\n",
    "\n",
    "class AttentionModule_stage3(nn.Module):\n",
    "\n",
    "    # input image size is 14*14\n",
    "    def __init__(self, in_channels, out_channels, size1=(14, 14)):\n",
    "        super(AttentionModule_stage3, self).__init__()\n",
    "        self.first_residual_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.trunk_branches = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "         )\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.softmax1_blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "\n",
    "        self.softmax2_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.last_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_residual_blocks(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "        out_mpool1 = self.mpool1(x)\n",
    "        out_softmax1 = self.softmax1_blocks(out_mpool1)\n",
    "\n",
    "        out_interp1 = self.interpolation1(out_softmax1) + out_trunk\n",
    "        out_softmax2 = self.softmax2_blocks(out_interp1)\n",
    "        out = (1 + out_softmax2) * out_trunk\n",
    "        out_last = self.last_blocks(out)\n",
    "\n",
    "        return out_last\n",
    "\n",
    "class ResidualAttentionNet_56(nn.Module):\n",
    "\n",
    "    # for input size 112\n",
    "    def __init__(self, feature_dim=512, drop_ratio=0.4):\n",
    "        super(ResidualAttentionNet_56, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual_block1 = ResidualBlock(64, 256)\n",
    "        self.attention_module1 = AttentionModule_stage1(256, 256)\n",
    "        self.residual_block2 = ResidualBlock(256, 512, 2)\n",
    "        self.attention_module2 = AttentionModule_stage2(512, 512)\n",
    "        self.residual_block3 = ResidualBlock(512, 512, 2)\n",
    "        self.attention_module3 = AttentionModule_stage3(512, 512)\n",
    "        self.residual_block4 = ResidualBlock(512, 512, 2)\n",
    "        self.residual_block5 = ResidualBlock(512, 512)\n",
    "        self.residual_block6 = ResidualBlock(512, 512)\n",
    "        self.output_layer = nn.Sequential(nn.BatchNorm2d(512),\n",
    "                                          nn.Dropout(drop_ratio),\n",
    "                                          Flatten(),\n",
    "                                          nn.Linear(512 * 7 * 7, feature_dim),\n",
    "                                          nn.BatchNorm1d(feature_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.mpool1(out)\n",
    "        # print(out.data)\n",
    "        out = self.residual_block1(out)\n",
    "        out = self.attention_module1(out)\n",
    "        out = self.residual_block2(out)\n",
    "        out = self.attention_module2(out)\n",
    "        out = self.residual_block3(out)\n",
    "        # print(out.data)\n",
    "        out = self.attention_module3(out)\n",
    "        out = self.residual_block4(out)\n",
    "        out = self.residual_block5(out)\n",
    "        out = self.residual_block6(out)\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResidualAttentionNet_92(nn.Module):\n",
    "\n",
    "    # for input size 112\n",
    "    def __init__(self, feature_dim=512, drop_ratio=0.4):\n",
    "        super(ResidualAttentionNet_92, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual_block1 = ResidualBlock(64, 256)\n",
    "        self.attention_module1 = AttentionModule_stage1(256, 256)\n",
    "        self.residual_block2 = ResidualBlock(256, 512, 2)\n",
    "        self.attention_module2 = AttentionModule_stage2(512, 512)\n",
    "        self.attention_module2_2 = AttentionModule_stage2(512, 512)  # tbq add\n",
    "        self.residual_block3 = ResidualBlock(512, 1024, 2)\n",
    "        self.attention_module3 = AttentionModule_stage3(1024, 1024)\n",
    "        self.attention_module3_2 = AttentionModule_stage3(1024, 1024)  # tbq add\n",
    "        self.attention_module3_3 = AttentionModule_stage3(1024, 1024)  # tbq add\n",
    "        self.residual_block4 = ResidualBlock(1024, 2048, 2)\n",
    "        self.residual_block5 = ResidualBlock(2048, 2048)\n",
    "        self.residual_block6 = ResidualBlock(2048, 2048)\n",
    "        self.output_layer = nn.Sequential(nn.BatchNorm2d(2048),\n",
    "                                          nn.Dropout(drop_ratio),\n",
    "                                          Flatten(),\n",
    "                                          nn.Linear(2048 * 7 * 7, feature_dim),\n",
    "                                          nn.BatchNorm1d(feature_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.mpool1(out)\n",
    "        # print(out.data)\n",
    "        out = self.residual_block1(out)\n",
    "        out = self.attention_module1(out)\n",
    "        out = self.residual_block2(out)\n",
    "        out = self.attention_module2(out)\n",
    "        out = self.attention_module2_2(out)\n",
    "        out = self.residual_block3(out)\n",
    "        # print(out.data)\n",
    "        out = self.attention_module3(out)\n",
    "        out = self.attention_module3_2(out)\n",
    "        out = self.attention_module3_3(out)\n",
    "        out = self.residual_block4(out)\n",
    "        out = self.residual_block5(out)\n",
    "        out = self.residual_block6(out)\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArcMarginProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:23.970789Z",
     "start_time": "2020-07-18T15:13:23.957786Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.ArcMarginProduct import ArcMarginProduct\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575, s=32.0, m=0.50, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "\n",
    "        # make the function cos(theta+m) monotonic decreasing while theta in [0,180]\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        # cos(theta)\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        # cos(theta + m)\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where((cosine - self.th) > 0, phi, cosine - self.mm)\n",
    "\n",
    "        #one_hot = torch.zeros(cosine.size(), device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output = output * self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiMarginProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:24.359788Z",
     "start_time": "2020-07-18T15:13:24.341787Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.MultiMarginProduct import MultiMarginProduct\n",
    "class MultiMarginProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575, s=32.0, m1=0.20, m2=0.35, easy_margin=False):\n",
    "        super(MultiMarginProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.s = s\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m1 = math.cos(m1)\n",
    "        self.sin_m1 = math.sin(m1)\n",
    "\n",
    "        # make the function cos(theta+m) monotonic decreasing while theta in [0,180]\n",
    "        self.th = math.cos(math.pi - m1)\n",
    "        self.mm = math.sin(math.pi - m1) * m1\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        # cos(theta)\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        # cos(theta + m1)\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m1 - sine * self.sin_m1\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where((cosine - self.th) > 0, phi, cosine - self.mm)\n",
    "\n",
    "\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine) # additive angular margin\n",
    "        output = output - one_hot * self.m2 # additive cosine margin\n",
    "        output = output * self.s\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosineMarginProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:24.754325Z",
     "start_time": "2020-07-18T15:13:24.740322Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.CosineMarginProduct import CosineMarginProduct\n",
    "class CosineMarginProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575, s=30.0, m=0.35):\n",
    "        super(CosineMarginProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        # one_hot = torch.zeros(cosine.size(), device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1.0)\n",
    "\n",
    "        output = self.s * (cosine - one_hot * self.m)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InnerProduct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:13:25.030323Z",
     "start_time": "2020-07-18T15:13:25.023329Z"
    }
   },
   "outputs": [],
   "source": [
    "# from margin.InnerProduct import InnerProduct\n",
    "class InnerProduct(nn.Module):\n",
    "    def __init__(self, in_feature=128, out_feature=10575):\n",
    "        super(InnerProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # label not used\n",
    "        output = F.linear(input, self.weight)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:15:58.848538Z",
     "start_time": "2020-07-18T15:13:25.542322Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F0709CC8>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/test (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F0709CC8>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/test (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F0709CC8>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "[WinError 10061]      \n",
      "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F8891488>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F8891488>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F8891488>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F17A3C48>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /events (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17A3C48>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /events (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17A3C48>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F07099C8>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /events (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F07099C8>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /events (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F07099C8>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88A8688>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A8688>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A8688>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F070DEC8>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070DEC8>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070DEC8>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88B24C8>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88B24C8>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88B24C8>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88A56C8>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A56C8>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A56C8>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88B8DC8>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88B8DC8>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88B8DC8>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F17A3C08>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17A3C08>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17A3C08>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88A7608>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A7608>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A7608>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F071CE08>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F071CE08>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F071CE08>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F0709688>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F0709688>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F0709688>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F8894CC8>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F8894CC8>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F8894CC8>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F88A5288>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A5288>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F88A5288>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F070D148>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070D148>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070D148>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F17D1308>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17D1308>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F17D1308>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B7F070DB48>: Failed to establish a new connection: [WinError 10061]      \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\", line 639, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\retry.py\", line 388, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070DB48>: Failed to establish a new connection: [WinError 10061]      '))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 555, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\", line 508, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /update (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B7F070DB48>: Failed to establish a new connection: [WinError 10061]      '))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061]      ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-277cd113c6d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-277cd113c6d9>\u001b[0m in \u001b[0;36mplot_curves\u001b[1;34m(self, d, iters, title, xlabel, ylabel)\u001b[0m\n\u001b[0;32m     16\u001b[0m                       \u001b[0mwin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                       \u001b[0mopts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                       update=None if self.index == 0 else 'append')\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mline\u001b[1;34m(self, Y, X, win, env, opts, update, name)\u001b[0m\n\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m         return self.scatter(X=linedata, Y=labels, opts=opts, win=win, env=env,\n\u001b[1;32m-> 1715\u001b[1;33m                             update=update, name=name)\n\u001b[0m\u001b[0;32m   1716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1717\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mpytorch_wrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, X, Y, win, env, opts, update, name)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[0mendpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'update'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_send\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mpytorch_wrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36m_send\u001b[1;34m(self, msg, endpoint, quiet, from_log, create)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \"{0}:{1}{2}/{3}\".format(self.server, self.port,\n\u001b[0;32m    710\u001b[0m                                         self.base_url, endpoint),\n\u001b[1;32m--> 711\u001b[1;33m                 \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m             )\n\u001b[0;32m    713\u001b[0m         except (\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\visdom\\__init__.py\u001b[0m in \u001b[0;36m_handle_post\u001b[1;34m(self, url, data)\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \"\"\"\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'POST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    506\u001b[0m         }\n\u001b[0;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 )\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;31m# Reset the timeout for the recv() on the socket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 encode_chunked=False):\n\u001b[0;32m   1251\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[1;31m# default charset of iso-8859-1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"\\r\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 141\u001b[1;33m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from utils.visualize import Visualizer\n",
    "class Visualizer():\n",
    "    def __init__(self, env='default', **kwargs):\n",
    "        self.vis = visdom.Visdom(env=env, **kwargs)\n",
    "        self.index = 1\n",
    "\n",
    "    def plot_curves(self, d, iters, title='loss', xlabel='iters', ylabel='accuracy'):\n",
    "        name = list(d.keys())\n",
    "        val = list(d.values())\n",
    "        if len(val) == 1:\n",
    "            y = np.array(val)\n",
    "        else:\n",
    "            y = np.array(val).reshape(-1, len(val))\n",
    "        self.vis.line(Y=y,\n",
    "                      X=np.array([self.index]),\n",
    "                      win=title,\n",
    "                      opts=dict(legend=name, title = title, xlabel=xlabel, ylabel=ylabel),\n",
    "                      update=None if self.index == 0 else 'append')\n",
    "        self.index = iters\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    vis = Visualizer(env='test')\n",
    "    for i in range(10):\n",
    "        x = i\n",
    "        y = 2 * i\n",
    "        z = 4 * i\n",
    "        vis.plot_curves({'train': x, 'test': y}, iters=i, title='train')\n",
    "        vis.plot_curves({'train': z, 'test': y, 'val': i}, iters=i, title='test')\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ligging.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:26.391541Z",
     "start_time": "2020-07-18T15:16:26.384543Z"
    }
   },
   "outputs": [],
   "source": [
    "# from utils.logging import init_log\n",
    "def init_log(output_dir):\n",
    "    logging.basicConfig(level=logging.DEBUG,\n",
    "                        format='%(asctime)s %(message)s',\n",
    "                        datefmt='%Y%m%d-%H:%M:%S',\n",
    "                        filename=os.path.join(output_dir, 'log.log'),\n",
    "                        filemode='w')\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    logging.getLogger('').addHandler(console)\n",
    "    return logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "## casia_sebface.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:32.320541Z",
     "start_time": "2020-07-18T15:16:32.304541Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.casia_webface import CASIAWebFace\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "\n",
    "class CASIAWebFace(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "        with open(file_list) as f:\n",
    "            img_label_list = f.read().splitlines()\n",
    "        for info in img_label_list:\n",
    "            image_path, label_name = info.split(' ')\n",
    "            image_list.append(image_path)\n",
    "            label_list.append(int(label_name))\n",
    "\n",
    "        self.image_list = image_list\n",
    "        self.label_list = label_list\n",
    "        self.class_nums = len(np.unique(self.label_list))\n",
    "        print(\"dataset size: \", len(self.image_list), '/', self.class_nums)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_list[index]\n",
    "        label = self.label_list[index]\n",
    "\n",
    "        img = self.loader(os.path.join(self.root, img_path))\n",
    "\n",
    "        # random flip with ratio of 0.5\n",
    "        flip = np.random.choice(2) * 2 - 1\n",
    "        if flip == 1:\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lfw.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:33.070542Z",
     "start_time": "2020-07-18T15:16:33.040548Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.lfw import LFW\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "class LFW(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.nameLs = []\n",
    "        self.nameRs = []\n",
    "        self.folds = []\n",
    "        self.flags = []\n",
    "\n",
    "        with open(file_list) as f:\n",
    "            pairs = f.read().splitlines()[1:]\n",
    "        for i, p in enumerate(pairs):\n",
    "            p = p.split('\\t')\n",
    "            if len(p) == 3:\n",
    "                nameL = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[1]))\n",
    "                nameR = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[2]))\n",
    "                fold = i // 600\n",
    "                flag = 1\n",
    "            elif len(p) == 4:\n",
    "                nameL = p[0] + '/' + p[0] + '_' + '{:04}.jpg'.format(int(p[1]))\n",
    "                nameR = p[2] + '/' + p[2] + '_' + '{:04}.jpg'.format(int(p[3]))\n",
    "                fold = i // 600\n",
    "                flag = -1\n",
    "            self.nameLs.append(nameL)\n",
    "            self.nameRs.append(nameR)\n",
    "            self.folds.append(fold)\n",
    "            self.flags.append(flag)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_l = self.loader(os.path.join(self.root, self.nameLs[index]))\n",
    "        img_r = self.loader(os.path.join(self.root, self.nameRs[index]))\n",
    "        imglist = [img_l, cv2.flip(img_l, 1), img_r, cv2.flip(img_r, 1)]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = self.transform(imglist[i])\n",
    "\n",
    "            imgs = imglist\n",
    "            return imgs\n",
    "        else:\n",
    "            imgs = [torch.from_numpy(i) for i in imglist]\n",
    "            return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nameLs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agedb.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:34.213546Z",
     "start_time": "2020-07-18T15:16:34.196541Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.agedb import AgeDB30\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "class AgeDB30(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.nameLs = []\n",
    "        self.nameRs = []\n",
    "        self.folds = []\n",
    "        self.flags = []\n",
    "\n",
    "        with open(file_list) as f:\n",
    "            pairs = f.read().splitlines()\n",
    "        for i, p in enumerate(pairs):\n",
    "            p = p.split(' ')\n",
    "            nameL = p[0]\n",
    "            nameR = p[1]\n",
    "            fold = i // 600\n",
    "            flag = int(p[2])\n",
    "\n",
    "            self.nameLs.append(nameL)\n",
    "            self.nameRs.append(nameR)\n",
    "            self.folds.append(fold)\n",
    "            self.flags.append(flag)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_l = self.loader(os.path.join(self.root, self.nameLs[index]))\n",
    "        img_r = self.loader(os.path.join(self.root, self.nameRs[index]))\n",
    "        imglist = [img_l, cv2.flip(img_l, 1), img_r, cv2.flip(img_r, 1)]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = self.transform(imglist[i])\n",
    "\n",
    "            imgs = imglist\n",
    "            return imgs\n",
    "        else:\n",
    "            imgs = [torch.from_numpy(i) for i in imglist]\n",
    "            return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nameLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cfp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:35.533545Z",
     "start_time": "2020-07-18T15:16:35.508539Z"
    }
   },
   "outputs": [],
   "source": [
    "# from dataset.cfp import CFP_FP\n",
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)\n",
    "\n",
    "class CFP_FP(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.nameLs = []\n",
    "        self.nameRs = []\n",
    "        self.folds = []\n",
    "        self.flags = []\n",
    "\n",
    "        with open(file_list) as f:\n",
    "            pairs = f.read().splitlines()\n",
    "        for i, p in enumerate(pairs):\n",
    "            p = p.split(' ')\n",
    "            nameL = p[0]\n",
    "            nameR = p[1]\n",
    "            fold = i // 700\n",
    "            flag = int(p[2])\n",
    "\n",
    "            self.nameLs.append(nameL)\n",
    "            self.nameRs.append(nameR)\n",
    "            self.folds.append(fold)\n",
    "            self.flags.append(flag)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_l = self.loader(os.path.join(self.root, self.nameLs[index]))\n",
    "        img_r = self.loader(os.path.join(self.root, self.nameRs[index]))\n",
    "        imglist = [img_l, cv2.flip(img_l, 1), img_r, cv2.flip(img_r, 1)]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(imglist)):\n",
    "                imglist[i] = self.transform(imglist[i])\n",
    "\n",
    "            imgs = imglist\n",
    "            return imgs\n",
    "        else:\n",
    "            imgs = [torch.from_numpy(i) for i in imglist]\n",
    "            return imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nameLs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval_lfw.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:36.786539Z",
     "start_time": "2020-07-18T15:16:36.727539Z"
    }
   },
   "outputs": [],
   "source": [
    "# from eval_lfw import evaluation_10_fold, getFeatureFromTorch\n",
    "def getAccuracy(scores, flags, threshold):\n",
    "    p = np.sum(scores[flags == 1] > threshold)\n",
    "    n = np.sum(scores[flags == -1] < threshold)\n",
    "    return 1.0 * (p + n) / len(scores)\n",
    "\n",
    "def getThreshold(scores, flags, thrNum):\n",
    "    accuracys = np.zeros((2 * thrNum + 1, 1))\n",
    "    thresholds = np.arange(-thrNum, thrNum + 1) * 1.0 / thrNum\n",
    "    for i in range(2 * thrNum + 1):\n",
    "        accuracys[i] = getAccuracy(scores, flags, thresholds[i])\n",
    "    max_index = np.squeeze(accuracys == np.max(accuracys))\n",
    "    bestThreshold = np.mean(thresholds[max_index])\n",
    "    return bestThreshold\n",
    "\n",
    "def evaluation_10_fold(feature_path='./result/cur_epoch_result.mat'):\n",
    "    ACCs = np.zeros(10)\n",
    "    result = scipy.io.loadmat(feature_path)\n",
    "    for i in range(10):\n",
    "        fold = result['fold']\n",
    "        flags = result['flag']\n",
    "        featureLs = result['fl']\n",
    "        featureRs = result['fr']\n",
    "\n",
    "        valFold = fold != i\n",
    "        testFold = fold == i\n",
    "        flags = np.squeeze(flags)\n",
    "\n",
    "        mu = np.mean(np.concatenate((featureLs[valFold[0], :], featureRs[valFold[0], :]), 0), 0)\n",
    "        mu = np.expand_dims(mu, 0)\n",
    "        featureLs = featureLs - mu\n",
    "        featureRs = featureRs - mu\n",
    "        featureLs = featureLs / np.expand_dims(np.sqrt(np.sum(np.power(featureLs, 2), 1)), 1)\n",
    "        featureRs = featureRs / np.expand_dims(np.sqrt(np.sum(np.power(featureRs, 2), 1)), 1)\n",
    "\n",
    "        scores = np.sum(np.multiply(featureLs, featureRs), 1)\n",
    "        threshold = getThreshold(scores[valFold[0]], flags[valFold[0]], 10000)\n",
    "        ACCs[i] = getAccuracy(scores[testFold[0]], flags[testFold[0]], threshold)\n",
    "\n",
    "    return ACCs\n",
    "\n",
    "def loadModel(data_root, file_list, backbone_net, gpus='0', resume=None):\n",
    "\n",
    "    if backbone_net == 'MobileFace':\n",
    "        net = mobilefacenet.MobileFaceNet()\n",
    "    elif backbone_net == 'CBAM_50':\n",
    "        net = cbam.CBAMResNet(50, feature_dim=args.feature_dim, mode='ir')\n",
    "    elif backbone_net == 'CBAM_50_SE':\n",
    "        net = cbam.CBAMResNet(50, feature_dim=args.feature_dim, mode='ir_se')\n",
    "    elif backbone_net == 'CBAM_100':\n",
    "        net = cbam.CBAMResNet(100, feature_dim=args.feature_dim, mode='ir')\n",
    "    elif backbone_net == 'CBAM_100_SE':\n",
    "        net = cbam.CBAMResNet(100, feature_dim=args.feature_dim, mode='ir_se')\n",
    "    else:\n",
    "        print(backbone_net, ' is not available!')\n",
    "\n",
    "    # gpu init\n",
    "    multi_gpus = False\n",
    "    if len(gpus.split(',')) > 1:\n",
    "        multi_gpus = True\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    net.load_state_dict(torch.load(resume)['net_state_dict'])\n",
    "\n",
    "    if multi_gpus:\n",
    "        net = DataParallel(net).to(device)\n",
    "    else:\n",
    "        net = net.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 1.0] -> [-1.0,1.0]\n",
    "    ])\n",
    "    lfw_dataset = LFW(data_root, file_list, transform=transform)\n",
    "    lfw_loader = torch.utils.data.DataLoader(lfw_dataset, batch_size=128,\n",
    "                                             shuffle=False, num_workers=2, drop_last=False)\n",
    "\n",
    "    return net.eval(), device, lfw_dataset, lfw_loader\n",
    "\n",
    "def getFeatureFromTorch(feature_save_dir, net, device, data_set, data_loader):\n",
    "    featureLs = None\n",
    "    featureRs = None\n",
    "    count = 0\n",
    "    for data in data_loader:\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "        count += data[0].size(0)\n",
    "        #print('extracing deep features from the face pair {}...'.format(count))\n",
    "        with torch.no_grad():\n",
    "            res = [net(d).data.cpu().numpy() for d in data]\n",
    "        featureL = np.concatenate((res[0], res[1]), 1)\n",
    "        featureR = np.concatenate((res[2], res[3]), 1)\n",
    "        # print(featureL.shape, featureR.shape)\n",
    "        if featureLs is None:\n",
    "            featureLs = featureL\n",
    "        else:\n",
    "            featureLs = np.concatenate((featureLs, featureL), 0)\n",
    "        if featureRs is None:\n",
    "            featureRs = featureR\n",
    "        else:\n",
    "            featureRs = np.concatenate((featureRs, featureR), 0)\n",
    "        # print(featureLs.shape, featureRs.shape)\n",
    "\n",
    "    result = {'fl': featureLs, 'fr': featureRs, 'fold': data_set.folds, 'flag': data_set.flags}\n",
    "    scipy.io.savemat(feature_save_dir, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:38.248541Z",
     "start_time": "2020-07-18T15:16:38.241538Z"
    }
   },
   "outputs": [],
   "source": [
    "def img_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = cv2.imread(path)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img] * 3, 2)\n",
    "            return img\n",
    "    except IOError:\n",
    "        print('Cannot load image ' + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:39.145538Z",
     "start_time": "2020-07-18T15:16:39.140542Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 1.0] -> [-1.0,1.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:16:40.002543Z",
     "start_time": "2020-07-18T15:16:39.984552Z"
    }
   },
   "outputs": [],
   "source": [
    "class CASIAWebFace(data.Dataset):\n",
    "    def __init__(self, root, file_list, transform=None, loader=img_loader):\n",
    "\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "        with open(file_list) as f:\n",
    "            img_label_list = f.read().splitlines()\n",
    "        for info in img_label_list:\n",
    "            image_path, label_name = info.split('\\t')[1:]\n",
    "            image_list.append(image_path)\n",
    "            label_list.append(int(label_name))\n",
    "\n",
    "        self.image_list = image_list\n",
    "        self.label_list = label_list\n",
    "        self.class_nums = len(np.unique(self.label_list))\n",
    "        print(\"dataset size: \", len(self.image_list), '/', self.class_nums)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_list[index]\n",
    "        label = self.label_list[index]\n",
    "\n",
    "        img = self.loader(os.path.join(self.root, img_path))\n",
    "\n",
    "        # random flip with ratio of 0.5\n",
    "        flip = np.random.choice(2) * 2 - 1\n",
    "        if flip == 1:\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:12.560596Z",
     "start_time": "2020-07-18T15:17:12.554595Z"
    }
   },
   "outputs": [],
   "source": [
    "# gpu init\n",
    "multi_gpus = False\n",
    "if len(args.gpus.split(',')) > 1:\n",
    "    multi_gpus = True\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpus\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:13.061593Z",
     "start_time": "2020-07-18T15:17:13.053593Z"
    }
   },
   "outputs": [],
   "source": [
    "# log init\n",
    "save_dir = os.path.join(args.save_dir, args.model_pre + args.backbone.upper() + '_' + datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "if os.path.exists(save_dir):\n",
    "    raise NameError('model dir exists!')\n",
    "os.makedirs(save_dir)\n",
    "logging = init_log(save_dir)\n",
    "_print = logging.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:13.947602Z",
     "start_time": "2020-07-18T15:17:13.935593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset size:  590 / 3\n"
     ]
    }
   ],
   "source": [
    "# dataset loader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 1.0] -> [-1.0,1.0]\n",
    "])\n",
    "# validation dataset\n",
    "print(args.train_root)\n",
    "trainset = CASIAWebFace(args.train_root, args.train_file_list, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:16.479597Z",
     "start_time": "2020-07-18T15:17:16.463593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.class_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:17.859593Z",
     "start_time": "2020-07-18T15:17:17.841592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/small_vgg/small_vgg_112x112/train/n000001/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0002_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0003_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0005_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0007_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0008_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0015_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0018_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0021_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0023_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0024_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0026_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0027_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0028_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0029_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0031_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0032_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0033_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0034_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0035_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0036_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0037_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0038_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0039_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0040_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0041_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0042_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0043_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0045_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0047_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0048_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0049_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0051_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0052_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0054_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0055_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0056_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0058_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0059_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0060_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0061_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0062_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0063_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0064_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0065_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0066_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0067_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0068_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0069_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0070_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0071_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0072_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0073_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0074_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0075_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0076_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0077_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0078_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0079_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0080_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0081_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0082_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0083_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0084_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0085_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0086_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0087_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0089_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0090_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0092_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0094_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0095_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0096_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_05.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_07.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_08.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0098_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0099_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0101_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0102_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0103_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0104_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0105_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0106_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0107_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0108_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0109_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0110_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0111_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0114_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0115_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0116_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0117_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0118_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0119_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0120_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0121_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0122_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0123_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0124_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0125_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0126_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0127_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0129_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0130_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0131_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0132_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0133_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0134_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0135_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0136_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0137_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0138_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0139_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0140_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0141_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0142_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0143_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0144_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0146_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0147_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0149_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0151_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0153_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0154_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0155_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0156_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0157_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0158_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0159_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0162_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0163_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0164_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0167_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0168_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0171_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0172_07.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0173_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0174_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0175_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0176_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0177_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0178_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0179_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0180_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0181_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0182_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0183_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0184_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0185_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0186_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0187_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0188_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0190_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0193_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0194_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0195_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0196_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0197_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0199_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0200_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0201_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0202_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0203_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0204_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0205_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0206_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0208_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0211_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0212_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0214_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0215_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0217_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0218_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0219_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0220_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0221_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0222_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0224_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0227_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0228_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0231_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0235_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0237_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0238_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0239_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0240_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0241_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0242_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0243_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0245_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0246_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0248_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0250_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0253_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0255_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0256_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0257_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0259_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0260_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0261_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0262_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0264_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0266_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0267_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0268_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0272_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0276_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0277_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0278_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0280_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0282_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0283_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0284_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0285_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0287_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0288_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0291_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0295_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0296_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0297_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0298_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0300_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0302_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0303_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0305_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0009_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0012_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0025_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0027_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0028_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0030_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0032_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0035_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0038_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0039_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0040_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0043_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0044_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0045_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0046_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0049_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0002_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0003_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0004_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0005_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0007_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0008_05.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0009_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0012_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0015_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0018_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0021_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0023_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0024_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0026_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0027_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0028_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0002_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0003_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0005_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0007_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0008_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0015_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0018_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0021_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0023_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0024_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0026_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0027_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0028_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0029_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0031_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0032_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0033_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0034_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0035_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0036_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0037_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0038_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0039_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0040_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0041_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0042_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0043_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0045_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0047_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0048_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0049_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0051_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0052_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0054_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0055_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0056_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0058_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0059_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0060_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0061_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0062_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0063_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0064_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0065_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0066_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0067_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0068_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0069_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0070_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0071_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0072_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0073_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0074_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0075_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0076_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0077_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0078_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0079_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0080_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0081_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0082_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0083_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0084_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0085_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0086_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0087_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0089_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0090_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0092_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0094_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0095_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0096_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_05.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_07.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0097_08.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0098_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0099_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0101_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0102_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0103_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0104_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0105_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0106_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0107_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0108_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0109_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0110_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0111_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0114_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0115_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0116_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0117_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0118_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0119_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0120_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0121_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0122_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0123_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0124_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0125_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0126_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0127_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0129_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0130_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0131_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0132_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0133_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0134_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0135_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0136_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0137_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0138_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0139_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0140_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0141_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0142_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0143_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0144_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0146_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0147_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0149_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0151_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0153_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0154_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0155_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0156_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0157_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0158_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0159_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0162_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0163_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0164_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0167_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0168_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0171_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0172_07.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0173_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0174_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0175_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0176_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0177_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0178_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0179_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0180_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0181_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0182_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0183_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0184_06.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0185_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0186_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0187_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0188_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0190_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0193_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0194_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0195_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0196_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0197_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0199_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0200_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0201_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0202_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0203_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0204_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0205_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0206_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0208_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0211_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0212_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0214_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0215_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0217_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0218_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0219_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0220_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0221_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0222_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0224_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0227_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0228_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0231_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0235_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0237_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0238_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0239_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0240_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0241_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0242_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0243_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0245_04.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0246_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0248_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0250_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0253_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0255_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0256_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0257_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0259_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0260_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0261_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0262_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0264_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0266_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0267_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0268_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0272_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0276_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0277_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0278_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0280_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0282_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0283_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0284_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0285_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0287_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0288_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0291_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0295_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0296_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0297_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0298_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0300_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0302_03.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0303_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000001/0305_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0009_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0012_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0025_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0027_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0028_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0030_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0032_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0035_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0038_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0039_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0040_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0043_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0044_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0045_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0046_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000009/0049_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0001_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0002_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0003_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0004_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0005_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0006_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0007_02.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0008_05.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0009_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0010_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0011_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0012_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0013_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0014_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0015_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0016_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0017_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0018_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0019_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0020_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0021_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0022_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0023_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0024_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0026_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0027_01.jpg',\n",
       " '../data/small_vgg/small_vgg_112x112/train/n000029/0028_01.jpg']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:26.936594Z",
     "start_time": "2020-07-18T15:17:26.930595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001B7F8874248>\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size,\n",
    "                                          shuffle=True,  drop_last=False)   # num_workers=8,\n",
    "print(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:28.621601Z",
     "start_time": "2020-07-18T15:17:28.615600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:30.103595Z",
     "start_time": "2020-07-18T15:17:30.077594Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/sda/lfw/pairs.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2e4601ab5f1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlfwdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLFW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlfw_test_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlfw_file_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m lfwloader = torch.utils.data.DataLoader(lfwdataset, batch_size=128,\n\u001b[0;32m      4\u001b[0m                                          shuffle=False, num_workers=4, drop_last=False)\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# agedbdataset = AgeDB30(args.agedb_test_root, args.agedb_file_list, transform=transform)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a0c985e125e4>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, file_list, transform, loader)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mpairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/sda/lfw/pairs.txt'"
     ]
    }
   ],
   "source": [
    "# test dataset\n",
    "lfwdataset = LFW(args.lfw_test_root, args.lfw_file_list, transform=transform)\n",
    "lfwloader = torch.utils.data.DataLoader(lfwdataset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=4, drop_last=False)\n",
    "# agedbdataset = AgeDB30(args.agedb_test_root, args.agedb_file_list, transform=transform)\n",
    "# agedbloader = torch.utils.data.DataLoader(agedbdataset, batch_size=128,\n",
    "#                                         shuffle=False, num_workers=4, drop_last=False)\n",
    "# cfpfpdataset = CFP_FP(args.cfpfp_test_root, args.cfpfp_file_list, transform=transform)\n",
    "# cfpfploader = torch.utils.data.DataLoader(cfpfpdataset, batch_size=128,\n",
    "#                                           shuffle=False, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:39.034594Z",
     "start_time": "2020-07-18T15:17:37.005593Z"
    }
   },
   "outputs": [],
   "source": [
    "# define backbone and margin layer\n",
    "if args.backbone == 'MobileFace':\n",
    "    net = MobileFaceNet()\n",
    "elif args.backbone == 'Res50_IR':\n",
    "    net = CBAMResNet(50, feature_dim=args.feature_dim, mode='ir')\n",
    "elif args.backbone == 'SERes50_IR':\n",
    "    net = CBAMResNet(50, feature_dim=args.feature_dim, mode='ir_se')\n",
    "elif args.backbone == 'Res100_IR':\n",
    "    net = CBAMResNet(100, feature_dim=args.feature_dim, mode='ir')\n",
    "elif args.backbone == 'SERes100_IR':\n",
    "    net = CBAMResNet(100, feature_dim=args.feature_dim, mode='ir_se')\n",
    "elif args.backbone == 'Attention_56':\n",
    "    net = ResidualAttentionNet_56(feature_dim=args.feature_dim)\n",
    "elif args.backbone == 'Attention_92':\n",
    "    net = ResidualAttentionNet_92(feature_dim=args.feature_dim)\n",
    "else:\n",
    "    print(args.backbone, ' is not available!')\n",
    "\n",
    "if args.margin_type == 'ArcFace':\n",
    "    margin = ArcMarginProduct(args.feature_dim, trainset.class_nums, s=args.scale_size)\n",
    "elif args.margin_type == 'MultiMargin':\n",
    "    margin = MultiMarginProduct(args.feature_dim, trainset.class_nums, s=args.scale_size)\n",
    "elif args.margin_type == 'CosFace':\n",
    "    margin = CosineMarginProduct(args.feature_dim, trainset.class_nums, s=args.scale_size)\n",
    "elif args.margin_type == 'Softmax':\n",
    "    margin = InnerProduct(args.feature_dim, trainset.class_nums)\n",
    "elif args.margin_type == 'SphereFace':\n",
    "    pass\n",
    "else:\n",
    "    print(args.margin_type, 'is not available!')\n",
    "\n",
    "if args.resume:\n",
    "    print('resume the model parameters from: ', args.net_path, args.margin_path)\n",
    "    net.load_state_dict(torch.load(args.net_path)['net_state_dict'])\n",
    "    margin.load_state_dict(torch.load(args.margin_path)['net_state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:39.068596Z",
     "start_time": "2020-07-18T15:17:39.037594Z"
    }
   },
   "outputs": [],
   "source": [
    "# define optimizers for different layer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer_ft = optim.SGD([\n",
    "    {'params': net.parameters(), 'weight_decay': 5e-4},\n",
    "    {'params': margin.parameters(), 'weight_decay': 5e-4}\n",
    "], lr=0.1, momentum=0.9, nesterov=True)\n",
    "exp_lr_scheduler = lr_scheduler.MultiStepLR(optimizer_ft, milestones=[6, 11, 16], gamma=0.1)\n",
    "\n",
    "if multi_gpus:\n",
    "    net = DataParallel(net).to(device)\n",
    "    margin = DataParallel(margin).to(device)\n",
    "else:\n",
    "    net = net.to(device)\n",
    "    margin = margin.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:41.402596Z",
     "start_time": "2020-07-18T15:17:41.398600Z"
    }
   },
   "outputs": [],
   "source": [
    "best_lfw_acc = 0.0\n",
    "best_lfw_iters = 0\n",
    "best_agedb30_acc = 0.0\n",
    "best_agedb30_iters = 0\n",
    "best_cfp_fp_acc = 0.0\n",
    "best_cfp_fp_iters = 0\n",
    "total_iters = 0\n",
    "# vis = Visualizer(env=args.model_pre + args.backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:46:25.496113Z",
     "start_time": "2020-07-18T15:19:37.522554Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1/18 ...\n",
      "Train Epoch: 1/18 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([14, 3, 112, 112]) torch.Size([14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2/18 ...\n",
      "Train Epoch: 2/18 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
      "len(data) 2 torch.Size([32, 3, 112, 112]) torch.Size([32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-67aadb0a69ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmargin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0moptimizer_ft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.total_epoch + 1):\n",
    "# while(1):\n",
    "    exp_lr_scheduler.step()\n",
    "    # train model\n",
    "    _print('Train Epoch: {}/{} ...'.format(epoch, args.total_epoch))\n",
    "    net.train()\n",
    "\n",
    "    since = time.time()\n",
    "    for data in trainloader:\n",
    "        print('len(data)', len(data), data[0].shape, data[1].shape)\n",
    "        img, label = data[0].to(device), data[1].to(device)\n",
    "        optimizer_ft.zero_grad()\n",
    "\n",
    "        raw_logits = net(img)\n",
    "        output = margin(raw_logits, label)\n",
    "        total_loss = criterion(output, label)\n",
    "        total_loss.backward()\n",
    "        optimizer_ft.step()\n",
    "\n",
    "        total_iters += 1\n",
    "        # print train information\n",
    "        if total_iters % 100 == 0:\n",
    "            # current training accuracy\n",
    "            _, predict = torch.max(output.data, 1)\n",
    "            total = label.size(0)\n",
    "            correct = (np.array(predict.cpu()) == np.array(label.data.cpu())).sum()\n",
    "            time_cur = (time.time() - since) / 100\n",
    "            since = time.time()\n",
    "#             vis.plot_curves({'softmax loss': total_loss.item()}, iters=total_iters, title='train loss',\n",
    "#                             xlabel='iters', ylabel='train loss')\n",
    "#             vis.plot_curves({'train accuracy': correct / total}, iters=total_iters, title='train accuracy', xlabel='iters',\n",
    "#                             ylabel='train accuracy')\n",
    "\n",
    "            _print(\"Iters: {:0>6d}/[{:0>2d}], loss: {:.4f}, train_accuracy: {:.4f}, time: {:.2f} s/iter, learning rate: {}\".format(total_iters, epoch, total_loss.item(), correct/total, time_cur, exp_lr_scheduler.get_lr()[0]))\n",
    "\n",
    "        # save model\n",
    "        if total_iters % args.save_freq == 0:\n",
    "            msg = 'Saving checkpoint: {}'.format(total_iters)\n",
    "            _print(msg)\n",
    "            if multi_gpus:\n",
    "                net_state_dict = net.module.state_dict()\n",
    "                margin_state_dict = margin.module.state_dict()\n",
    "            else:\n",
    "                net_state_dict = net.state_dict()\n",
    "                margin_state_dict = margin.state_dict()\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.mkdir(save_dir)\n",
    "            torch.save({\n",
    "                'iters': total_iters,\n",
    "                'net_state_dict': net_state_dict},\n",
    "                os.path.join(save_dir, 'Iter_%06d_net.ckpt' % total_iters))\n",
    "            torch.save({\n",
    "                'iters': total_iters,\n",
    "                'net_state_dict': margin_state_dict},\n",
    "                os.path.join(save_dir, 'Iter_%06d_margin.ckpt' % total_iters))\n",
    "\n",
    "print('finishing training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T15:17:08.497592Z",
     "start_time": "2020-07-18T15:17:08.485603Z"
    }
   },
   "outputs": [],
   "source": [
    "args = EasyDict()\n",
    "\n",
    "# args.train_root ='../data/faces_webface_112x112/imgs'    #'train image root')\n",
    "# args.train_file_list= '../data/faces_webface_112x112/train2.lst'    #'train list')\n",
    "args.train_root =''    #'train image root')\n",
    "args.train_file_list= '../data/small_vgg/train.lst'    #'train list')\n",
    "args.lfw_test_root='../data/lfw/'     #'lfw image root')\n",
    "args.lfw_file_list='/media/sda/lfw/pairs.txt'     #'lfw pair file list')\n",
    "args.agedb_test_root='/media/sda/AgeDB-30/agedb30_align_112'     #'agedb image root')\n",
    "args.agedb_file_list='/media/sda/AgeDB-30/agedb_30_pair.txt'     #'agedb pair file list')\n",
    "args.cfpfp_test_root='/media/sda/CFP-FP/cfp_fp_aligned_112'     #'agedb image root')\n",
    "args.cfpfp_file_list='/media/sda/CFP-FP/cfp_fp_pair.txt'     #'agedb pair file list')\n",
    "\n",
    "args.backbone='SERes100_IR'     #'MobileFace, Res50_IR, SERes50_IR, Res100_IR, SERes100_IR, Attention_56, Attention_92')\n",
    "args.margin_type='ArcFace'     #'ArcFace, CosFace, SphereFace, MultiMargin, Softmax')\n",
    "args.feature_dim=512     #'feature dimension, 128 or 512')\n",
    "args.scale_size=32.0     #'scale size')\n",
    "args.batch_size=32     #'batch size', defalut : 200\n",
    "args.total_epoch=18     #'total epochs')\n",
    "\n",
    "args.save_freq=3000     #'save frequency')\n",
    "args.test_freq=3000     #'test frequency')\n",
    "args.resume=False     #'resume model')\n",
    "args.net_path=''     #'resume model')\n",
    "args.margin_path=''     #'resume model')\n",
    "args.save_dir='./model'     #'model save dir')\n",
    "args.model_pre='SERES100_'     #'model prefix')\n",
    "args.gpus='0,1,2,3'     #'model prefix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T13:07:00.415862Z",
     "start_time": "2020-07-18T13:07:00.403856Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "# root = 'D:/data/webface_align_112'\n",
    "# file_list = 'D:/data/webface_align_train.list'\n",
    "root = '../data/faces_webface_112x112/imgs'  \n",
    "file_list = '../data/small_vgg/small_vgg_112x112.lst'\n",
    "print(os.path.isdir(root), os.path.isfile(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166.094px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
